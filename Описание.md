# **Text classification task**

## **Задание:**

Имеется датафрейм train.csv, содержащий 2 столбца: ***Description*** (далее переименнованный в ***'text'***) - содержащий тексты на естественном языке произвольной длины и ***Label*** - определяющий класс каждого текста.

Необходимо:
1) Обучить модель классификации
2) Сделать скрипт для предсказания моделью класса фразы из test.csv и подсчёта метрик(accuracy, precision, recall, macro-f1)
Замечание: Нельзя использовать LLM не для получения эмбеддингов => для получения эмбеддингов можно воспользоваться готовыми предобученными LLM, что мы и сделаем.

## **Решение:**

**Шаг 1: Изучение данных**

- ***Label*** - представляет из себя массив, содержащий классы тестов (всего 4 уникальных класса)
- ***text*** - представляет из себя массив, содержащий тексты произвольной длины
- Исходный размер выборки = 45381

Первое что необходимо сделать, это проверить данные на наличие пропусков(в том числе пустых строк) и дубликатов:
1) Количество пропусков/пустых строк = 0 
2) Количество дубликатов = 19051 - почти **42%** выборки дубликаты, которые необходимо удалить для получения репрезентативных результатов

Таким образом, общее количество наблюдений после удаления выбросов будет равно **26330**.

Посмотрим, как распределяются классы в итоговом датафрейме:
![image](https://github.com/IlinMatvey/Text_classification/assets/112751928/94b25f6c-8702-471b-aac8-39d0e60e2910)

Как видно из гистаграммы, в данных преобладает класс 0, однако критичного дисбаланса классов не наблюдается.

**Шаг 2: Предобработка исходного текста**

Препроцессинг помогает подготовить текстовые данные к следующим этапам анализа или обработки и позволяет привести текст к единой форме. Основные этапы препроцессинга:
1) Приведение текста к нижнему регистру
2) Удаление лишних пробелов
3) Удаление стоп-слов
4) Удаление знаков препинания
5) Лемматизация токенов(слов)

В дальнейшем мы будем оценивать качество моделей классификации на исходном и предобработанном тексте для оценки влияния препроцессинга на качество итоговых моделей.

P.s. Для векторизации текста мы будем использовать уже готовые LLM модели, в которых уже зашита примитивная предобработка текста, данный этап можно считать показательным и как мы увидим в дальнейшем это никак значимо не повлияет на качество моделей классификации.

**Шаг 3: Векторизация текста: получение эмбеддингов**

Для преобразования текста в числовой формат в данном тестовом задании будут использоваться 3 предобученные LLM для создания эмбеддингов предложений:
1) **all-mpnet-base-v2** - преобразует текст произвольной длины в числовой вектор размером 768.
2) **all-MiniLM-L6-v2** - преобразует текст произвольной длины в числовой вектор размером 384.
3) **universal-sentence-encoder** - преобразует текст произвольной длины в числовой вектор размером 512.

Links:

- https://sbert.net/docs/pretrained_models.html
- https://tfhub.dev/google/universal-sentence-encoder/4

Данные модели были выбраны для сравнения из следующих соображений:
1) all-mpnet-base-v2 - является лучшей моделью для создания эмбедингов предложений по оценки их качества для решения различных задач в сфере NLP
2) all-MiniLM-L6-v2  - работает в 5 раз быстрее чем all-mpnet-base-v2, и тоже показывает хорошие результаты
3) universal-sentence-encoder - топовая модель от компании Google

Данные модели также будут сравниваться между собой для выявления наиболее подходящей для решения поставленной задачи.

**Шаг 4: Выбор наилучшей модели классификации текстов**

Разделение данных на обучающую, варидационную и тестовую выборки:
1) Данные разбиваются на 2 части: тренировочная выборка - 80%, тестовая выборка - 20 % **с сохранением распределения классов относительно исходного распределения.**
2) Тренировочная выборка с использованием метода кросс-валидации разделяется на 4 равных части, и итеративно каждая из этих частей выступает в качестве валидационной выборки, в то время как оставшиеся части формируют обучающую выборку.

Таким образом в обучении модели учавствует только 80% данных, а 20% используются для итогового тестирования.

В качестве алгоритмов классификации были выбраны следующие модели: 
Модель | Количество блоков   
:-------|:--------
LSTM | 64
LSTM | 128
LSTM | 256
GRU | 64
GRU | 128
GRU | 256

Модель | Количество нейронов скрытого слоя   
:-------|:--------
Perceptron | 64
Perceptron | 128
Perceptron | 256
Perceptron | 512

В каждой из этих моделей используется 2 метода борьбы с переобучением:
1) Наличие метода Dropout со значение 0.5
2) Наличие EarlyStopping

Таблица с результатами оценки модели на тестовой выборке:













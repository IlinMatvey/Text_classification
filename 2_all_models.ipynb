{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Сравнение моделей классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Импортирование необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional, GRU, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка данных и первичная предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('all_embeddings_text.csv')\n",
    "df_2 = pd.read_csv('all_embeddings_prep_text.csv')\n",
    "\n",
    "df['1_prep_text'] = df_2['1_prep_text']\n",
    "df['2_prep_text'] = df_2['2_prep_text']\n",
    "df['3_prep_text'] = df_2['3_prep_text']\n",
    "\n",
    "def parse_string_to_list(s):\n",
    "    clean_s = s.strip('[]') \n",
    "    numbers = clean_s.split() \n",
    "    return [float(num) for num in numbers]\n",
    "\n",
    "for i in range(1,4):\n",
    "    df[f'{i}_text'] = df[f'{i}_text'].apply(parse_string_to_list)\n",
    "    df[f'{i}_prep_text'] = df[f'{i}_prep_text'].apply(parse_string_to_list)\n",
    "\n",
    "df['Label'] = df['Label'].astype(int)\n",
    "\n",
    "embeddings_models = ['all_mpnet_base_v2', 'all_MiniLM_L6_v2', 'Universal-sentence-encoder']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Визуальный анализ распределения данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_counts = df['Label'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "class_counts.plot(kind='bar', color='skyblue')\n",
    "plt.title('Распределение классов')\n",
    "plt.xlabel('Метка класса')\n",
    "plt.ylabel('Количество')\n",
    "plt.xticks(rotation=0)  \n",
    "for i, count in enumerate(class_counts):\n",
    "    plt.text(i, count + 0.1, str(count), ha='center', va='bottom') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сравнение моделей LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип модели построения энбэдингов: all_mpnet_base_v2\n",
      "Тип модели классификации: LSTM_64\n",
      "Наличие предобработки текста: no\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8154 - loss: 0.6442 - val_accuracy: 0.9351 - val_loss: 0.2281\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9357 - loss: 0.2183 - val_accuracy: 0.9383 - val_loss: 0.2132\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9448 - loss: 0.1968 - val_accuracy: 0.9406 - val_loss: 0.2046\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9480 - loss: 0.1865 - val_accuracy: 0.9421 - val_loss: 0.2013\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9484 - loss: 0.1815 - val_accuracy: 0.9406 - val_loss: 0.2007\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9517 - loss: 0.1709 - val_accuracy: 0.9411 - val_loss: 0.1989\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9542 - loss: 0.1635 - val_accuracy: 0.9417 - val_loss: 0.1956\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9571 - loss: 0.1476 - val_accuracy: 0.9438 - val_loss: 0.1950\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1442 - val_accuracy: 0.9423 - val_loss: 0.1976\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9556 - loss: 0.1557 - val_accuracy: 0.9434 - val_loss: 0.1934\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9525 - loss: 0.1642 - val_accuracy: 0.9525 - val_loss: 0.1519\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9567 - loss: 0.1519 - val_accuracy: 0.9525 - val_loss: 0.1536\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9542 - loss: 0.1477 - val_accuracy: 0.9518 - val_loss: 0.1598\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1473 - val_accuracy: 0.9626 - val_loss: 0.1290\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1407 - val_accuracy: 0.9622 - val_loss: 0.1310\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9545 - loss: 0.1522 - val_accuracy: 0.9618 - val_loss: 0.1342\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9560 - loss: 0.1480 - val_accuracy: 0.9639 - val_loss: 0.1180\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9594 - loss: 0.1358 - val_accuracy: 0.9633 - val_loss: 0.1196\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1420 - val_accuracy: 0.9635 - val_loss: 0.1211\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Тип модели построения энбэдингов: all_mpnet_base_v2\n",
      "Тип модели классификации: LSTM_64\n",
      "Наличие предобработки текста: yes\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8101 - loss: 0.6521 - val_accuracy: 0.9354 - val_loss: 0.2371\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9345 - loss: 0.2343 - val_accuracy: 0.9402 - val_loss: 0.2235\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9392 - loss: 0.2095 - val_accuracy: 0.9406 - val_loss: 0.2203\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9488 - loss: 0.1884 - val_accuracy: 0.9417 - val_loss: 0.2143\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9510 - loss: 0.1763 - val_accuracy: 0.9430 - val_loss: 0.2109\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9485 - loss: 0.1774 - val_accuracy: 0.9425 - val_loss: 0.2085\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9495 - loss: 0.1750 - val_accuracy: 0.9419 - val_loss: 0.2088\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9527 - loss: 0.1621 - val_accuracy: 0.9444 - val_loss: 0.2057\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9560 - loss: 0.1529 - val_accuracy: 0.9457 - val_loss: 0.2017\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9568 - loss: 0.1475 - val_accuracy: 0.9444 - val_loss: 0.2035\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9560 - loss: 0.1571 - val_accuracy: 0.9529 - val_loss: 0.1655\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9529 - loss: 0.1624 - val_accuracy: 0.9506 - val_loss: 0.1695\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9547 - loss: 0.1588 - val_accuracy: 0.9487 - val_loss: 0.1706\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9504 - loss: 0.1658 - val_accuracy: 0.9575 - val_loss: 0.1410\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9513 - loss: 0.1651 - val_accuracy: 0.9569 - val_loss: 0.1450\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9519 - loss: 0.1616 - val_accuracy: 0.9559 - val_loss: 0.1472\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9523 - loss: 0.1613 - val_accuracy: 0.9609 - val_loss: 0.1298\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.1575 - val_accuracy: 0.9599 - val_loss: 0.1313\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9543 - loss: 0.1493 - val_accuracy: 0.9575 - val_loss: 0.1349\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Тип модели построения энбэдингов: all_mpnet_base_v2\n",
      "Тип модели классификации: LSTM_128\n",
      "Наличие предобработки текста: no\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.8094 - loss: 0.5830 - val_accuracy: 0.9373 - val_loss: 0.2219\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9396 - loss: 0.2094 - val_accuracy: 0.9411 - val_loss: 0.2092\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9466 - loss: 0.1807 - val_accuracy: 0.9413 - val_loss: 0.2021\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9520 - loss: 0.1672 - val_accuracy: 0.9400 - val_loss: 0.2008\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9517 - loss: 0.1704 - val_accuracy: 0.9417 - val_loss: 0.1989\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9560 - loss: 0.1548 - val_accuracy: 0.9440 - val_loss: 0.1953\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9554 - loss: 0.1513 - val_accuracy: 0.9427 - val_loss: 0.1977\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9548 - loss: 0.1504 - val_accuracy: 0.9438 - val_loss: 0.1928\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9574 - loss: 0.1402 - val_accuracy: 0.9455 - val_loss: 0.1909\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9602 - loss: 0.1363 - val_accuracy: 0.9459 - val_loss: 0.1935\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9565 - loss: 0.1566 - val_accuracy: 0.9531 - val_loss: 0.1473\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9579 - loss: 0.1365 - val_accuracy: 0.9546 - val_loss: 0.1514\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9634 - loss: 0.1223 - val_accuracy: 0.9544 - val_loss: 0.1500\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9543 - loss: 0.1516 - val_accuracy: 0.9632 - val_loss: 0.1227\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9596 - loss: 0.1368 - val_accuracy: 0.9637 - val_loss: 0.1241\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9602 - loss: 0.1337 - val_accuracy: 0.9622 - val_loss: 0.1291\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9567 - loss: 0.1447 - val_accuracy: 0.9692 - val_loss: 0.1112\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9572 - loss: 0.1398 - val_accuracy: 0.9660 - val_loss: 0.1147\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9591 - loss: 0.1312 - val_accuracy: 0.9652 - val_loss: 0.1165\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Тип модели построения энбэдингов: all_mpnet_base_v2\n",
      "Тип модели классификации: LSTM_128\n",
      "Наличие предобработки текста: yes\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.8250 - loss: 0.5807 - val_accuracy: 0.9366 - val_loss: 0.2304\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9417 - loss: 0.2070 - val_accuracy: 0.9402 - val_loss: 0.2201\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9445 - loss: 0.1980 - val_accuracy: 0.9425 - val_loss: 0.2153\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9463 - loss: 0.1867 - val_accuracy: 0.9417 - val_loss: 0.2110\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9536 - loss: 0.1650 - val_accuracy: 0.9428 - val_loss: 0.2081\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9507 - loss: 0.1658 - val_accuracy: 0.9440 - val_loss: 0.2070\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9515 - loss: 0.1633 - val_accuracy: 0.9453 - val_loss: 0.2049\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9555 - loss: 0.1512 - val_accuracy: 0.9444 - val_loss: 0.2038\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9552 - loss: 0.1544 - val_accuracy: 0.9466 - val_loss: 0.2035\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9547 - loss: 0.1462 - val_accuracy: 0.9442 - val_loss: 0.2044\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9524 - loss: 0.1697 - val_accuracy: 0.9527 - val_loss: 0.1558\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9564 - loss: 0.1443 - val_accuracy: 0.9512 - val_loss: 0.1661\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9583 - loss: 0.1460 - val_accuracy: 0.9521 - val_loss: 0.1631\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9529 - loss: 0.1607 - val_accuracy: 0.9596 - val_loss: 0.1330\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9551 - loss: 0.1557 - val_accuracy: 0.9596 - val_loss: 0.1341\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9582 - loss: 0.1443 - val_accuracy: 0.9588 - val_loss: 0.1430\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9507 - loss: 0.1643 - val_accuracy: 0.9622 - val_loss: 0.1186\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9570 - loss: 0.1476 - val_accuracy: 0.9609 - val_loss: 0.1249\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9613 - loss: 0.1320 - val_accuracy: 0.9620 - val_loss: 0.1256\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Тип модели построения энбэдингов: all_mpnet_base_v2\n",
      "Тип модели классификации: LSTM_256\n",
      "Наличие предобработки текста: no\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 27ms/step - accuracy: 0.8343 - loss: 0.5211 - val_accuracy: 0.9379 - val_loss: 0.2203\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.9430 - loss: 0.1949 - val_accuracy: 0.9389 - val_loss: 0.2046\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.9492 - loss: 0.1762 - val_accuracy: 0.9415 - val_loss: 0.2005\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9499 - loss: 0.1679 - val_accuracy: 0.9423 - val_loss: 0.1962\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9531 - loss: 0.1565 - val_accuracy: 0.9417 - val_loss: 0.1949\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9530 - loss: 0.1537 - val_accuracy: 0.9444 - val_loss: 0.1964\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.9592 - loss: 0.1451 - val_accuracy: 0.9411 - val_loss: 0.1995\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - accuracy: 0.9527 - loss: 0.1615 - val_accuracy: 0.9510 - val_loss: 0.1647\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9558 - loss: 0.1486 - val_accuracy: 0.9506 - val_loss: 0.1691\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9577 - loss: 0.1437 - val_accuracy: 0.9508 - val_loss: 0.1705\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9519 - loss: 0.1613 - val_accuracy: 0.9597 - val_loss: 0.1397\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.9546 - loss: 0.1573 - val_accuracy: 0.9603 - val_loss: 0.1430\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9575 - loss: 0.1421 - val_accuracy: 0.9577 - val_loss: 0.1462\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9529 - loss: 0.1563 - val_accuracy: 0.9618 - val_loss: 0.1299\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9547 - loss: 0.1521 - val_accuracy: 0.9615 - val_loss: 0.1325\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.9606 - loss: 0.1362 - val_accuracy: 0.9596 - val_loss: 0.1333\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Тип модели построения энбэдингов: all_mpnet_base_v2\n",
      "Тип модели классификации: LSTM_256\n",
      "Наличие предобработки текста: yes\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 29ms/step - accuracy: 0.8378 - loss: 0.5231 - val_accuracy: 0.9387 - val_loss: 0.2273\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.9392 - loss: 0.2161 - val_accuracy: 0.9411 - val_loss: 0.2166\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 28ms/step - accuracy: 0.9416 - loss: 0.1961 - val_accuracy: 0.9417 - val_loss: 0.2124\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 33ms/step - accuracy: 0.9491 - loss: 0.1730 - val_accuracy: 0.9413 - val_loss: 0.2123\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 33ms/step - accuracy: 0.9491 - loss: 0.1706 - val_accuracy: 0.9425 - val_loss: 0.2072\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 31ms/step - accuracy: 0.9541 - loss: 0.1525 - val_accuracy: 0.9442 - val_loss: 0.2052\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 28ms/step - accuracy: 0.9536 - loss: 0.1520 - val_accuracy: 0.9447 - val_loss: 0.2065\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 28ms/step - accuracy: 0.9575 - loss: 0.1452 - val_accuracy: 0.9445 - val_loss: 0.2004\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 29ms/step - accuracy: 0.9553 - loss: 0.1451 - val_accuracy: 0.9480 - val_loss: 0.2000\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.9614 - loss: 0.1318 - val_accuracy: 0.9464 - val_loss: 0.1983\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - accuracy: 0.9559 - loss: 0.1486 - val_accuracy: 0.9582 - val_loss: 0.1428\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 28ms/step - accuracy: 0.9595 - loss: 0.1346 - val_accuracy: 0.9554 - val_loss: 0.1458\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 28ms/step - accuracy: 0.9637 - loss: 0.1297 - val_accuracy: 0.9529 - val_loss: 0.1544\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 28ms/step - accuracy: 0.9553 - loss: 0.1509 - val_accuracy: 0.9618 - val_loss: 0.1226\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.9603 - loss: 0.1368 - val_accuracy: 0.9620 - val_loss: 0.1225\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 29ms/step - accuracy: 0.9625 - loss: 0.1256 - val_accuracy: 0.9594 - val_loss: 0.1278\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 28ms/step - accuracy: 0.9667 - loss: 0.1143 - val_accuracy: 0.9605 - val_loss: 0.1246\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 29ms/step - accuracy: 0.9596 - loss: 0.1323 - val_accuracy: 0.9706 - val_loss: 0.0981\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 28ms/step - accuracy: 0.9606 - loss: 0.1337 - val_accuracy: 0.9694 - val_loss: 0.1030\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.9647 - loss: 0.1187 - val_accuracy: 0.9685 - val_loss: 0.1059\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Тип модели построения энбэдингов: all_MiniLM_L6_v2\n",
      "Тип модели классификации: LSTM_64\n",
      "Наличие предобработки текста: no\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7830 - loss: 0.7423 - val_accuracy: 0.9250 - val_loss: 0.2653\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9287 - loss: 0.2492 - val_accuracy: 0.9282 - val_loss: 0.2514\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9351 - loss: 0.2261 - val_accuracy: 0.9330 - val_loss: 0.2426\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9393 - loss: 0.2121 - val_accuracy: 0.9332 - val_loss: 0.2393\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9391 - loss: 0.2137 - val_accuracy: 0.9343 - val_loss: 0.2413\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9430 - loss: 0.2014 - val_accuracy: 0.9345 - val_loss: 0.2376\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9468 - loss: 0.1921 - val_accuracy: 0.9352 - val_loss: 0.2354\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9470 - loss: 0.1872 - val_accuracy: 0.9339 - val_loss: 0.2354\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9450 - loss: 0.1901 - val_accuracy: 0.9351 - val_loss: 0.2363\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9469 - loss: 0.1794 - val_accuracy: 0.9345 - val_loss: 0.2335\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9444 - loss: 0.1947 - val_accuracy: 0.9461 - val_loss: 0.1873\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9462 - loss: 0.1893 - val_accuracy: 0.9444 - val_loss: 0.1947\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9485 - loss: 0.1817 - val_accuracy: 0.9447 - val_loss: 0.1950\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9404 - loss: 0.2014 - val_accuracy: 0.9525 - val_loss: 0.1652\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9481 - loss: 0.1866 - val_accuracy: 0.9521 - val_loss: 0.1673\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9446 - loss: 0.1873 - val_accuracy: 0.9518 - val_loss: 0.1674\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9414 - loss: 0.1995 - val_accuracy: 0.9535 - val_loss: 0.1526\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9421 - loss: 0.1964 - val_accuracy: 0.9535 - val_loss: 0.1548\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9507 - loss: 0.1759 - val_accuracy: 0.9516 - val_loss: 0.1593\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Тип модели построения энбэдингов: all_MiniLM_L6_v2\n",
      "Тип модели классификации: LSTM_64\n",
      "Наличие предобработки текста: yes\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7604 - loss: 0.7353 - val_accuracy: 0.9223 - val_loss: 0.2790\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9259 - loss: 0.2540 - val_accuracy: 0.9305 - val_loss: 0.2595\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9313 - loss: 0.2366 - val_accuracy: 0.9301 - val_loss: 0.2523\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9355 - loss: 0.2212 - val_accuracy: 0.9316 - val_loss: 0.2476\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9367 - loss: 0.2207 - val_accuracy: 0.9341 - val_loss: 0.2491\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9391 - loss: 0.2069 - val_accuracy: 0.9324 - val_loss: 0.2448\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9363 - loss: 0.2159 - val_accuracy: 0.9330 - val_loss: 0.2416\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9416 - loss: 0.2013 - val_accuracy: 0.9333 - val_loss: 0.2431\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9399 - loss: 0.2064 - val_accuracy: 0.9352 - val_loss: 0.2408\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9429 - loss: 0.1943 - val_accuracy: 0.9339 - val_loss: 0.2403\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9432 - loss: 0.1979 - val_accuracy: 0.9409 - val_loss: 0.1975\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9441 - loss: 0.1902 - val_accuracy: 0.9383 - val_loss: 0.2022\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9389 - loss: 0.2027 - val_accuracy: 0.9381 - val_loss: 0.2034\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9416 - loss: 0.2013 - val_accuracy: 0.9464 - val_loss: 0.1759\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9405 - loss: 0.2005 - val_accuracy: 0.9455 - val_loss: 0.1762\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9381 - loss: 0.1990 - val_accuracy: 0.9434 - val_loss: 0.1861\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9396 - loss: 0.2013 - val_accuracy: 0.9491 - val_loss: 0.1590\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9407 - loss: 0.2065 - val_accuracy: 0.9470 - val_loss: 0.1620\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9419 - loss: 0.1999 - val_accuracy: 0.9466 - val_loss: 0.1647\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Тип модели построения энбэдингов: all_MiniLM_L6_v2\n",
      "Тип модели классификации: LSTM_128\n",
      "Наличие предобработки текста: no\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7867 - loss: 0.6708 - val_accuracy: 0.9290 - val_loss: 0.2590\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9305 - loss: 0.2361 - val_accuracy: 0.9290 - val_loss: 0.2478\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9351 - loss: 0.2212 - val_accuracy: 0.9322 - val_loss: 0.2404\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9393 - loss: 0.2106 - val_accuracy: 0.9354 - val_loss: 0.2386\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9450 - loss: 0.1957 - val_accuracy: 0.9360 - val_loss: 0.2340\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9433 - loss: 0.1982 - val_accuracy: 0.9364 - val_loss: 0.2350\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9489 - loss: 0.1784 - val_accuracy: 0.9347 - val_loss: 0.2365\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9442 - loss: 0.1988 - val_accuracy: 0.9396 - val_loss: 0.2099\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9482 - loss: 0.1853 - val_accuracy: 0.9389 - val_loss: 0.2105\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9479 - loss: 0.1796 - val_accuracy: 0.9381 - val_loss: 0.2131\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9415 - loss: 0.1986 - val_accuracy: 0.9493 - val_loss: 0.1810\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9401 - loss: 0.2105 - val_accuracy: 0.9472 - val_loss: 0.1813\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9457 - loss: 0.1889 - val_accuracy: 0.9480 - val_loss: 0.1824\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9409 - loss: 0.2070 - val_accuracy: 0.9483 - val_loss: 0.1702\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9459 - loss: 0.1868 - val_accuracy: 0.9472 - val_loss: 0.1719\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9472 - loss: 0.1845 - val_accuracy: 0.9493 - val_loss: 0.1723\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Тип модели построения энбэдингов: all_MiniLM_L6_v2\n",
      "Тип модели классификации: LSTM_128\n",
      "Наличие предобработки текста: yes\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7692 - loss: 0.6659 - val_accuracy: 0.9275 - val_loss: 0.2689\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9286 - loss: 0.2450 - val_accuracy: 0.9305 - val_loss: 0.2549\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9335 - loss: 0.2200 - val_accuracy: 0.9311 - val_loss: 0.2497\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9357 - loss: 0.2162 - val_accuracy: 0.9314 - val_loss: 0.2456\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9361 - loss: 0.2131 - val_accuracy: 0.9339 - val_loss: 0.2426\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9424 - loss: 0.1941 - val_accuracy: 0.9320 - val_loss: 0.2455\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9428 - loss: 0.1930 - val_accuracy: 0.9351 - val_loss: 0.2397\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9400 - loss: 0.1955 - val_accuracy: 0.9343 - val_loss: 0.2419\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9417 - loss: 0.1826 - val_accuracy: 0.9337 - val_loss: 0.2412\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9421 - loss: 0.1994 - val_accuracy: 0.9379 - val_loss: 0.2073\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9440 - loss: 0.1972 - val_accuracy: 0.9371 - val_loss: 0.2125\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9456 - loss: 0.1918 - val_accuracy: 0.9396 - val_loss: 0.2103\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9397 - loss: 0.2082 - val_accuracy: 0.9444 - val_loss: 0.1817\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9418 - loss: 0.1936 - val_accuracy: 0.9466 - val_loss: 0.1814\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9438 - loss: 0.1881 - val_accuracy: 0.9436 - val_loss: 0.1824\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9448 - loss: 0.1839 - val_accuracy: 0.9445 - val_loss: 0.1820\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9440 - loss: 0.1930 - val_accuracy: 0.9493 - val_loss: 0.1592\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9454 - loss: 0.1873 - val_accuracy: 0.9442 - val_loss: 0.1630\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9458 - loss: 0.1907 - val_accuracy: 0.9470 - val_loss: 0.1621\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Тип модели построения энбэдингов: all_MiniLM_L6_v2\n",
      "Тип модели классификации: LSTM_256\n",
      "Наличие предобработки текста: no\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.8254 - loss: 0.6005 - val_accuracy: 0.9305 - val_loss: 0.2519\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9336 - loss: 0.2277 - val_accuracy: 0.9324 - val_loss: 0.2408\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9401 - loss: 0.2069 - val_accuracy: 0.9337 - val_loss: 0.2370\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.9385 - loss: 0.2132 - val_accuracy: 0.9351 - val_loss: 0.2374\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9436 - loss: 0.1991 - val_accuracy: 0.9316 - val_loss: 0.2396\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.9420 - loss: 0.2050 - val_accuracy: 0.9390 - val_loss: 0.2163\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.9454 - loss: 0.1892 - val_accuracy: 0.9373 - val_loss: 0.2186\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9424 - loss: 0.1959 - val_accuracy: 0.9389 - val_loss: 0.2218\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.9374 - loss: 0.2121 - val_accuracy: 0.9482 - val_loss: 0.1848\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9394 - loss: 0.1981 - val_accuracy: 0.9451 - val_loss: 0.1936\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9458 - loss: 0.1927 - val_accuracy: 0.9464 - val_loss: 0.1890\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9435 - loss: 0.2054 - val_accuracy: 0.9478 - val_loss: 0.1752\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9468 - loss: 0.1879 - val_accuracy: 0.9461 - val_loss: 0.1776\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9417 - loss: 0.1979 - val_accuracy: 0.9470 - val_loss: 0.1809\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Тип модели построения энбэдингов: all_MiniLM_L6_v2\n",
      "Тип модели классификации: LSTM_256\n",
      "Наличие предобработки текста: yes\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7952 - loss: 0.6059 - val_accuracy: 0.9261 - val_loss: 0.2683\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9251 - loss: 0.2498 - val_accuracy: 0.9311 - val_loss: 0.2518\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.9385 - loss: 0.2172 - val_accuracy: 0.9326 - val_loss: 0.2476\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9405 - loss: 0.2125 - val_accuracy: 0.9333 - val_loss: 0.2448\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.9369 - loss: 0.2068 - val_accuracy: 0.9332 - val_loss: 0.2441\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9401 - loss: 0.1997 - val_accuracy: 0.9351 - val_loss: 0.2422\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9440 - loss: 0.1866 - val_accuracy: 0.9356 - val_loss: 0.2397\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.9469 - loss: 0.1843 - val_accuracy: 0.9339 - val_loss: 0.2379\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.9452 - loss: 0.1799 - val_accuracy: 0.9364 - val_loss: 0.2381\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.9499 - loss: 0.1699 - val_accuracy: 0.9316 - val_loss: 0.2382\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9392 - loss: 0.1981 - val_accuracy: 0.9415 - val_loss: 0.1931\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.9460 - loss: 0.1790 - val_accuracy: 0.9425 - val_loss: 0.1988\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.9482 - loss: 0.1706 - val_accuracy: 0.9396 - val_loss: 0.1986\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9414 - loss: 0.1981 - val_accuracy: 0.9501 - val_loss: 0.1668\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.9484 - loss: 0.1796 - val_accuracy: 0.9493 - val_loss: 0.1687\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9450 - loss: 0.1765 - val_accuracy: 0.9445 - val_loss: 0.1753\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9412 - loss: 0.1966 - val_accuracy: 0.9518 - val_loss: 0.1504\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9451 - loss: 0.1876 - val_accuracy: 0.9516 - val_loss: 0.1537\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.9510 - loss: 0.1656 - val_accuracy: 0.9506 - val_loss: 0.1532\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Тип модели построения энбэдингов: Universal-sentence-encoder\n",
      "Тип модели классификации: LSTM_64\n",
      "Наличие предобработки текста: no\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7657 - loss: 0.7423 - val_accuracy: 0.9275 - val_loss: 0.2634\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9307 - loss: 0.2434 - val_accuracy: 0.9299 - val_loss: 0.2479\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9328 - loss: 0.2331 - val_accuracy: 0.9333 - val_loss: 0.2385\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9380 - loss: 0.2118 - val_accuracy: 0.9341 - val_loss: 0.2361\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9397 - loss: 0.2008 - val_accuracy: 0.9333 - val_loss: 0.2376\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9417 - loss: 0.1999 - val_accuracy: 0.9370 - val_loss: 0.2335\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9415 - loss: 0.1884 - val_accuracy: 0.9349 - val_loss: 0.2329\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9486 - loss: 0.1778 - val_accuracy: 0.9368 - val_loss: 0.2306\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9420 - loss: 0.1917 - val_accuracy: 0.9373 - val_loss: 0.2308\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9470 - loss: 0.1788 - val_accuracy: 0.9366 - val_loss: 0.2309\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9464 - loss: 0.1834 - val_accuracy: 0.9423 - val_loss: 0.1939\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9455 - loss: 0.1867 - val_accuracy: 0.9427 - val_loss: 0.1955\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9440 - loss: 0.1893 - val_accuracy: 0.9408 - val_loss: 0.2014\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9439 - loss: 0.1957 - val_accuracy: 0.9468 - val_loss: 0.1698\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9440 - loss: 0.1913 - val_accuracy: 0.9461 - val_loss: 0.1723\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9449 - loss: 0.1842 - val_accuracy: 0.9455 - val_loss: 0.1738\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9430 - loss: 0.1904 - val_accuracy: 0.9499 - val_loss: 0.1610\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9444 - loss: 0.1869 - val_accuracy: 0.9497 - val_loss: 0.1629\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9464 - loss: 0.1799 - val_accuracy: 0.9483 - val_loss: 0.1634\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Тип модели построения энбэдингов: Universal-sentence-encoder\n",
      "Тип модели классификации: LSTM_64\n",
      "Наличие предобработки текста: yes\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7482 - loss: 0.7458 - val_accuracy: 0.9212 - val_loss: 0.2772\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9280 - loss: 0.2464 - val_accuracy: 0.9248 - val_loss: 0.2558\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9326 - loss: 0.2245 - val_accuracy: 0.9275 - val_loss: 0.2495\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9367 - loss: 0.2126 - val_accuracy: 0.9261 - val_loss: 0.2515\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9361 - loss: 0.2144 - val_accuracy: 0.9284 - val_loss: 0.2474\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9385 - loss: 0.2017 - val_accuracy: 0.9301 - val_loss: 0.2470\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9376 - loss: 0.2013 - val_accuracy: 0.9316 - val_loss: 0.2437\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9456 - loss: 0.1837 - val_accuracy: 0.9314 - val_loss: 0.2437\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9454 - loss: 0.1861 - val_accuracy: 0.9313 - val_loss: 0.2432\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9426 - loss: 0.1867 - val_accuracy: 0.9320 - val_loss: 0.2428\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9429 - loss: 0.1994 - val_accuracy: 0.9430 - val_loss: 0.1886\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9446 - loss: 0.1911 - val_accuracy: 0.9423 - val_loss: 0.1922\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9472 - loss: 0.1859 - val_accuracy: 0.9389 - val_loss: 0.1970\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9401 - loss: 0.2036 - val_accuracy: 0.9474 - val_loss: 0.1658\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9435 - loss: 0.1891 - val_accuracy: 0.9453 - val_loss: 0.1704\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9427 - loss: 0.1975 - val_accuracy: 0.9461 - val_loss: 0.1734\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9387 - loss: 0.2010 - val_accuracy: 0.9491 - val_loss: 0.1580\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9436 - loss: 0.1932 - val_accuracy: 0.9487 - val_loss: 0.1605\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9434 - loss: 0.1823 - val_accuracy: 0.9463 - val_loss: 0.1632\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Тип модели построения энбэдингов: Universal-sentence-encoder\n",
      "Тип модели классификации: LSTM_128\n",
      "Наличие предобработки текста: no\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.8092 - loss: 0.6566 - val_accuracy: 0.9275 - val_loss: 0.2606\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9341 - loss: 0.2338 - val_accuracy: 0.9337 - val_loss: 0.2397\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9369 - loss: 0.2094 - val_accuracy: 0.9354 - val_loss: 0.2358\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9414 - loss: 0.1937 - val_accuracy: 0.9352 - val_loss: 0.2332\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9419 - loss: 0.1952 - val_accuracy: 0.9349 - val_loss: 0.2323\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9450 - loss: 0.1812 - val_accuracy: 0.9356 - val_loss: 0.2348\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9445 - loss: 0.1827 - val_accuracy: 0.9351 - val_loss: 0.2313\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9454 - loss: 0.1878 - val_accuracy: 0.9360 - val_loss: 0.2303\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9453 - loss: 0.1757 - val_accuracy: 0.9356 - val_loss: 0.2295\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9478 - loss: 0.1678 - val_accuracy: 0.9370 - val_loss: 0.2302\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9474 - loss: 0.1858 - val_accuracy: 0.9472 - val_loss: 0.1796\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9469 - loss: 0.1839 - val_accuracy: 0.9440 - val_loss: 0.1871\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9520 - loss: 0.1664 - val_accuracy: 0.9445 - val_loss: 0.1864\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9438 - loss: 0.1939 - val_accuracy: 0.9478 - val_loss: 0.1559\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9497 - loss: 0.1722 - val_accuracy: 0.9478 - val_loss: 0.1619\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9477 - loss: 0.1754 - val_accuracy: 0.9480 - val_loss: 0.1620\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9476 - loss: 0.1788 - val_accuracy: 0.9550 - val_loss: 0.1447\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9488 - loss: 0.1691 - val_accuracy: 0.9539 - val_loss: 0.1471\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9518 - loss: 0.1635 - val_accuracy: 0.9523 - val_loss: 0.1525\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Тип модели построения энбэдингов: Universal-sentence-encoder\n",
      "Тип модели классификации: LSTM_128\n",
      "Наличие предобработки текста: yes\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.7607 - loss: 0.6809 - val_accuracy: 0.9244 - val_loss: 0.2694\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9269 - loss: 0.2498 - val_accuracy: 0.9256 - val_loss: 0.2551\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9334 - loss: 0.2243 - val_accuracy: 0.9265 - val_loss: 0.2521\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9417 - loss: 0.1975 - val_accuracy: 0.9307 - val_loss: 0.2458\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9401 - loss: 0.2028 - val_accuracy: 0.9307 - val_loss: 0.2465\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9397 - loss: 0.1966 - val_accuracy: 0.9313 - val_loss: 0.2448\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9454 - loss: 0.1880 - val_accuracy: 0.9322 - val_loss: 0.2460\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9449 - loss: 0.1892 - val_accuracy: 0.9314 - val_loss: 0.2436\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9457 - loss: 0.1759 - val_accuracy: 0.9335 - val_loss: 0.2451\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.1709 - val_accuracy: 0.9339 - val_loss: 0.2409\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9464 - loss: 0.1855 - val_accuracy: 0.9478 - val_loss: 0.1790\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9457 - loss: 0.1772 - val_accuracy: 0.9445 - val_loss: 0.1844\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9512 - loss: 0.1727 - val_accuracy: 0.9436 - val_loss: 0.1873\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9431 - loss: 0.1901 - val_accuracy: 0.9501 - val_loss: 0.1585\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9435 - loss: 0.1867 - val_accuracy: 0.9495 - val_loss: 0.1603\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9467 - loss: 0.1802 - val_accuracy: 0.9495 - val_loss: 0.1628\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9434 - loss: 0.1834 - val_accuracy: 0.9518 - val_loss: 0.1509\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9473 - loss: 0.1756 - val_accuracy: 0.9493 - val_loss: 0.1550\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9485 - loss: 0.1651 - val_accuracy: 0.9514 - val_loss: 0.1546\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Тип модели построения энбэдингов: Universal-sentence-encoder\n",
      "Тип модели классификации: LSTM_256\n",
      "Наличие предобработки текста: no\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.8155 - loss: 0.5910 - val_accuracy: 0.9276 - val_loss: 0.2520\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9339 - loss: 0.2395 - val_accuracy: 0.9337 - val_loss: 0.2405\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.9390 - loss: 0.2109 - val_accuracy: 0.9341 - val_loss: 0.2368\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9410 - loss: 0.1945 - val_accuracy: 0.9345 - val_loss: 0.2333\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9456 - loss: 0.1852 - val_accuracy: 0.9335 - val_loss: 0.2356\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.9411 - loss: 0.1949 - val_accuracy: 0.9332 - val_loss: 0.2369\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9434 - loss: 0.1989 - val_accuracy: 0.9404 - val_loss: 0.2034\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9453 - loss: 0.1838 - val_accuracy: 0.9375 - val_loss: 0.2135\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9466 - loss: 0.1848 - val_accuracy: 0.9385 - val_loss: 0.2129\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9426 - loss: 0.1984 - val_accuracy: 0.9447 - val_loss: 0.1807\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9444 - loss: 0.1916 - val_accuracy: 0.9436 - val_loss: 0.1815\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9440 - loss: 0.1848 - val_accuracy: 0.9417 - val_loss: 0.1863\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9402 - loss: 0.2000 - val_accuracy: 0.9491 - val_loss: 0.1674\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9451 - loss: 0.1845 - val_accuracy: 0.9451 - val_loss: 0.1773\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9438 - loss: 0.1835 - val_accuracy: 0.9461 - val_loss: 0.1737\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Тип модели построения энбэдингов: Universal-sentence-encoder\n",
      "Тип модели классификации: LSTM_256\n",
      "Наличие предобработки текста: yes\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.7815 - loss: 0.6109 - val_accuracy: 0.9267 - val_loss: 0.2615\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9291 - loss: 0.2293 - val_accuracy: 0.9280 - val_loss: 0.2522\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.9382 - loss: 0.2094 - val_accuracy: 0.9292 - val_loss: 0.2471\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.9345 - loss: 0.2096 - val_accuracy: 0.9292 - val_loss: 0.2501\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9422 - loss: 0.1907 - val_accuracy: 0.9295 - val_loss: 0.2461\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9443 - loss: 0.1834 - val_accuracy: 0.9330 - val_loss: 0.2444\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.9416 - loss: 0.1835 - val_accuracy: 0.9335 - val_loss: 0.2420\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9463 - loss: 0.1800 - val_accuracy: 0.9337 - val_loss: 0.2422\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9478 - loss: 0.1742 - val_accuracy: 0.9345 - val_loss: 0.2425\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.9381 - loss: 0.2008 - val_accuracy: 0.9428 - val_loss: 0.1900\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9445 - loss: 0.1874 - val_accuracy: 0.9430 - val_loss: 0.1951\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.9475 - loss: 0.1759 - val_accuracy: 0.9425 - val_loss: 0.1985\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.9438 - loss: 0.1924 - val_accuracy: 0.9506 - val_loss: 0.1663\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9449 - loss: 0.1863 - val_accuracy: 0.9466 - val_loss: 0.1704\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9490 - loss: 0.1710 - val_accuracy: 0.9461 - val_loss: 0.1766\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9450 - loss: 0.1815 - val_accuracy: 0.9508 - val_loss: 0.1554\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9480 - loss: 0.1738 - val_accuracy: 0.9457 - val_loss: 0.1665\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9455 - loss: 0.1791 - val_accuracy: 0.9502 - val_loss: 0.1615\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "embeddings_models_list = []\n",
    "classification_models = []\n",
    "preprocessing_types = []\n",
    "acc_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "for i in range(1,4):\n",
    "    for lstm_size in [64, 128, 256]:\n",
    "            for prep_type in ['_text', '_prep_text']:\n",
    "\n",
    "                print(f'Тип модели построения энбэдингов: {embeddings_models[i-1]}')\n",
    "                print(f'Тип модели классификации: LSTM_{lstm_size}')\n",
    "\n",
    "                embeddings_models_list.append(embeddings_models[i-1])\n",
    "                classification_models.append(f'LSTM_{lstm_size}')\n",
    "                \n",
    "                X = np.array(df[f'{i}{prep_type}'].to_list())\n",
    "                labels = np.array(df['Label'])  \n",
    "\n",
    "                prep_type = 'yes' if prep_type == '_prep_text' else 'no'\n",
    "                print(f'Наличие предобработки текста: {prep_type}')\n",
    "                preprocessing_types.append(prep_type)\n",
    "\n",
    "                X_train_val, X_test, y_train_val, y_test = train_test_split(X, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "                model = Sequential()\n",
    "                model.add(Bidirectional(LSTM(lstm_size, input_shape=(1, X_train_val.shape[1]))))\n",
    "                model.add(Dropout(0.5))\n",
    "                model.add(Dense(4, activation='softmax'))  \n",
    "\n",
    "                model.compile(loss='categorical_crossentropy',\n",
    "                            optimizer='adam',\n",
    "                            metrics=['accuracy']) \n",
    "\n",
    "                y_train_val_categorical = to_categorical(y_train_val, num_classes=4)\n",
    "                y_test_categorical = to_categorical(y_test, num_classes=4)\n",
    "\n",
    "                n_splits = 4\n",
    "                kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "                for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X_train_val, y_train_val)):\n",
    "                    print(f\"Training fold {fold_idx + 1}/{n_splits}\")\n",
    "\n",
    "                    X_train = X_train_val[train_idx]\n",
    "                    y_train = y_train_val_categorical[train_idx]\n",
    "                    X_val = X_train_val[val_idx]\n",
    "                    y_val = y_train_val_categorical[val_idx]\n",
    "\n",
    "                    X_train_lstm = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "                    X_val_lstm = np.reshape(X_val, (X_val.shape[0], 1, X_val.shape[1]))\n",
    "\n",
    "                    early_stopping = EarlyStopping(monitor='val_loss', patience = 2, restore_best_weights=True)\n",
    "                    model.fit(X_train_lstm, y_train, validation_data=(X_val_lstm, y_val), epochs = 10, callbacks=[early_stopping])\n",
    "                \n",
    "                X_test_lstm = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "                y_pred_categorical = model.predict(X_test_lstm)\n",
    "                y_pred = y_pred_categorical.argmax(axis=1)\n",
    "\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision = precision_score(y_test, y_pred, average='macro')\n",
    "                recall = recall_score(y_test, y_pred, average='macro')\n",
    "                f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "                acc_list.append(accuracy)\n",
    "                precision_list.append(precision)\n",
    "                recall_list.append(recall)\n",
    "                f1_list.append(f1)\n",
    "\n",
    "lstm_results = pd.DataFrame({'embeddings_model': embeddings_models_list,\n",
    "                          'classification_model': classification_models,\n",
    "                          'preprocessing_has': preprocessing_types,\n",
    "                          'accuracy': acc_list,\n",
    "                          'precision_macro': precision_list,\n",
    "                          'recall_macro': recall_list,\n",
    "                          'f1_macro': f1_list})\n",
    "\n",
    "lstm_results.to_csv('lstm_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings_model</th>\n",
       "      <th>classification_model</th>\n",
       "      <th>preprocessing_has</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all_mpnet_base_v2</td>\n",
       "      <td>LSTM_64</td>\n",
       "      <td>no</td>\n",
       "      <td>0.952146</td>\n",
       "      <td>0.953867</td>\n",
       "      <td>0.949392</td>\n",
       "      <td>0.951495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all_mpnet_base_v2</td>\n",
       "      <td>LSTM_64</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.949297</td>\n",
       "      <td>0.950058</td>\n",
       "      <td>0.946428</td>\n",
       "      <td>0.948097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all_mpnet_base_v2</td>\n",
       "      <td>LSTM_128</td>\n",
       "      <td>no</td>\n",
       "      <td>0.950437</td>\n",
       "      <td>0.949691</td>\n",
       "      <td>0.949574</td>\n",
       "      <td>0.949617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all_mpnet_base_v2</td>\n",
       "      <td>LSTM_128</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.950817</td>\n",
       "      <td>0.950404</td>\n",
       "      <td>0.949853</td>\n",
       "      <td>0.950122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>all_mpnet_base_v2</td>\n",
       "      <td>LSTM_256</td>\n",
       "      <td>no</td>\n",
       "      <td>0.951196</td>\n",
       "      <td>0.949797</td>\n",
       "      <td>0.950774</td>\n",
       "      <td>0.950209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>all_mpnet_base_v2</td>\n",
       "      <td>LSTM_256</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.950627</td>\n",
       "      <td>0.950599</td>\n",
       "      <td>0.948875</td>\n",
       "      <td>0.949705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>all_MiniLM_L6_v2</td>\n",
       "      <td>LSTM_64</td>\n",
       "      <td>no</td>\n",
       "      <td>0.944170</td>\n",
       "      <td>0.944847</td>\n",
       "      <td>0.942394</td>\n",
       "      <td>0.943491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>all_MiniLM_L6_v2</td>\n",
       "      <td>LSTM_64</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.940942</td>\n",
       "      <td>0.941138</td>\n",
       "      <td>0.939058</td>\n",
       "      <td>0.940035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>all_MiniLM_L6_v2</td>\n",
       "      <td>LSTM_128</td>\n",
       "      <td>no</td>\n",
       "      <td>0.943411</td>\n",
       "      <td>0.943175</td>\n",
       "      <td>0.942090</td>\n",
       "      <td>0.942445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>all_MiniLM_L6_v2</td>\n",
       "      <td>LSTM_128</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.939992</td>\n",
       "      <td>0.940879</td>\n",
       "      <td>0.937730</td>\n",
       "      <td>0.939221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>all_MiniLM_L6_v2</td>\n",
       "      <td>LSTM_256</td>\n",
       "      <td>no</td>\n",
       "      <td>0.942461</td>\n",
       "      <td>0.943010</td>\n",
       "      <td>0.940862</td>\n",
       "      <td>0.941830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>all_MiniLM_L6_v2</td>\n",
       "      <td>LSTM_256</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.943411</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.941400</td>\n",
       "      <td>0.942545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Universal-sentence-encoder</td>\n",
       "      <td>LSTM_64</td>\n",
       "      <td>no</td>\n",
       "      <td>0.939992</td>\n",
       "      <td>0.939226</td>\n",
       "      <td>0.940437</td>\n",
       "      <td>0.939776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Universal-sentence-encoder</td>\n",
       "      <td>LSTM_64</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.937904</td>\n",
       "      <td>0.938081</td>\n",
       "      <td>0.937614</td>\n",
       "      <td>0.937780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Universal-sentence-encoder</td>\n",
       "      <td>LSTM_128</td>\n",
       "      <td>no</td>\n",
       "      <td>0.942461</td>\n",
       "      <td>0.942558</td>\n",
       "      <td>0.941944</td>\n",
       "      <td>0.942230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Universal-sentence-encoder</td>\n",
       "      <td>LSTM_128</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.938473</td>\n",
       "      <td>0.938363</td>\n",
       "      <td>0.938225</td>\n",
       "      <td>0.938271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Universal-sentence-encoder</td>\n",
       "      <td>LSTM_256</td>\n",
       "      <td>no</td>\n",
       "      <td>0.941132</td>\n",
       "      <td>0.940270</td>\n",
       "      <td>0.941842</td>\n",
       "      <td>0.941006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Universal-sentence-encoder</td>\n",
       "      <td>LSTM_256</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.939803</td>\n",
       "      <td>0.939577</td>\n",
       "      <td>0.938977</td>\n",
       "      <td>0.939244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              embeddings_model classification_model preprocessing_has  \\\n",
       "0            all_mpnet_base_v2              LSTM_64                no   \n",
       "1            all_mpnet_base_v2              LSTM_64               yes   \n",
       "2            all_mpnet_base_v2             LSTM_128                no   \n",
       "3            all_mpnet_base_v2             LSTM_128               yes   \n",
       "4            all_mpnet_base_v2             LSTM_256                no   \n",
       "5            all_mpnet_base_v2             LSTM_256               yes   \n",
       "6             all_MiniLM_L6_v2              LSTM_64                no   \n",
       "7             all_MiniLM_L6_v2              LSTM_64               yes   \n",
       "8             all_MiniLM_L6_v2             LSTM_128                no   \n",
       "9             all_MiniLM_L6_v2             LSTM_128               yes   \n",
       "10            all_MiniLM_L6_v2             LSTM_256                no   \n",
       "11            all_MiniLM_L6_v2             LSTM_256               yes   \n",
       "12  Universal-sentence-encoder              LSTM_64                no   \n",
       "13  Universal-sentence-encoder              LSTM_64               yes   \n",
       "14  Universal-sentence-encoder             LSTM_128                no   \n",
       "15  Universal-sentence-encoder             LSTM_128               yes   \n",
       "16  Universal-sentence-encoder             LSTM_256                no   \n",
       "17  Universal-sentence-encoder             LSTM_256               yes   \n",
       "\n",
       "    accuracy  precision_macro  recall_macro  f1_macro  \n",
       "0   0.952146         0.953867      0.949392  0.951495  \n",
       "1   0.949297         0.950058      0.946428  0.948097  \n",
       "2   0.950437         0.949691      0.949574  0.949617  \n",
       "3   0.950817         0.950404      0.949853  0.950122  \n",
       "4   0.951196         0.949797      0.950774  0.950209  \n",
       "5   0.950627         0.950599      0.948875  0.949705  \n",
       "6   0.944170         0.944847      0.942394  0.943491  \n",
       "7   0.940942         0.941138      0.939058  0.940035  \n",
       "8   0.943411         0.943175      0.942090  0.942445  \n",
       "9   0.939992         0.940879      0.937730  0.939221  \n",
       "10  0.942461         0.943010      0.940862  0.941830  \n",
       "11  0.943411         0.944000      0.941400  0.942545  \n",
       "12  0.939992         0.939226      0.940437  0.939776  \n",
       "13  0.937904         0.938081      0.937614  0.937780  \n",
       "14  0.942461         0.942558      0.941944  0.942230  \n",
       "15  0.938473         0.938363      0.938225  0.938271  \n",
       "16  0.941132         0.940270      0.941842  0.941006  \n",
       "17  0.939803         0.939577      0.938977  0.939244  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сравнение моделей GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип модели построения эмбеддингов: all_mpnet_base_v2\n",
      "Тип модели классификации: GRU_64\n",
      "Наличие предобработки текста: no\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8396 - loss: 0.5717 - val_accuracy: 0.9349 - val_loss: 0.2249\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9420 - loss: 0.2066 - val_accuracy: 0.9392 - val_loss: 0.2106\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9466 - loss: 0.1893 - val_accuracy: 0.9413 - val_loss: 0.2044\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9461 - loss: 0.1829 - val_accuracy: 0.9402 - val_loss: 0.2008\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9496 - loss: 0.1704 - val_accuracy: 0.9402 - val_loss: 0.1983\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9504 - loss: 0.1691 - val_accuracy: 0.9421 - val_loss: 0.1964\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9527 - loss: 0.1579 - val_accuracy: 0.9423 - val_loss: 0.1962\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9503 - loss: 0.1659 - val_accuracy: 0.9411 - val_loss: 0.2036\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9540 - loss: 0.1553 - val_accuracy: 0.9445 - val_loss: 0.1960\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9548 - loss: 0.1544 - val_accuracy: 0.9427 - val_loss: 0.1972\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9512 - loss: 0.1668 - val_accuracy: 0.9504 - val_loss: 0.1615\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9541 - loss: 0.1512 - val_accuracy: 0.9502 - val_loss: 0.1664\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9585 - loss: 0.1402 - val_accuracy: 0.9506 - val_loss: 0.1675\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9495 - loss: 0.1676 - val_accuracy: 0.9613 - val_loss: 0.1391\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9521 - loss: 0.1649 - val_accuracy: 0.9620 - val_loss: 0.1408\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9583 - loss: 0.1430 - val_accuracy: 0.9580 - val_loss: 0.1419\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9529 - loss: 0.1578 - val_accuracy: 0.9630 - val_loss: 0.1275\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9552 - loss: 0.1551 - val_accuracy: 0.9613 - val_loss: 0.1291\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9576 - loss: 0.1481 - val_accuracy: 0.9596 - val_loss: 0.1328\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Тип модели построения эмбеддингов: all_mpnet_base_v2\n",
      "Тип модели классификации: GRU_64\n",
      "Наличие предобработки текста: yes\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8463 - loss: 0.5694 - val_accuracy: 0.9364 - val_loss: 0.2297\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9364 - loss: 0.2251 - val_accuracy: 0.9379 - val_loss: 0.2209\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9416 - loss: 0.2064 - val_accuracy: 0.9406 - val_loss: 0.2143\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9490 - loss: 0.1796 - val_accuracy: 0.9428 - val_loss: 0.2111\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9457 - loss: 0.1821 - val_accuracy: 0.9413 - val_loss: 0.2087\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9508 - loss: 0.1740 - val_accuracy: 0.9432 - val_loss: 0.2077\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9508 - loss: 0.1729 - val_accuracy: 0.9427 - val_loss: 0.2112\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9511 - loss: 0.1743 - val_accuracy: 0.9440 - val_loss: 0.2072\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9541 - loss: 0.1615 - val_accuracy: 0.9421 - val_loss: 0.2057\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9541 - loss: 0.1567 - val_accuracy: 0.9445 - val_loss: 0.2033\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9509 - loss: 0.1651 - val_accuracy: 0.9506 - val_loss: 0.1674\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9498 - loss: 0.1676 - val_accuracy: 0.9495 - val_loss: 0.1720\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9550 - loss: 0.1540 - val_accuracy: 0.9491 - val_loss: 0.1727\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9481 - loss: 0.1745 - val_accuracy: 0.9607 - val_loss: 0.1406\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9501 - loss: 0.1749 - val_accuracy: 0.9578 - val_loss: 0.1437\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9519 - loss: 0.1631 - val_accuracy: 0.9571 - val_loss: 0.1470\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9502 - loss: 0.1729 - val_accuracy: 0.9597 - val_loss: 0.1293\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9543 - loss: 0.1545 - val_accuracy: 0.9575 - val_loss: 0.1355\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9525 - loss: 0.1580 - val_accuracy: 0.9561 - val_loss: 0.1383\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Тип модели построения эмбеддингов: all_mpnet_base_v2\n",
      "Тип модели классификации: GRU_128\n",
      "Наличие предобработки текста: no\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.8548 - loss: 0.5046 - val_accuracy: 0.9362 - val_loss: 0.2171\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9429 - loss: 0.1980 - val_accuracy: 0.9415 - val_loss: 0.2043\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9465 - loss: 0.1895 - val_accuracy: 0.9425 - val_loss: 0.2008\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9476 - loss: 0.1745 - val_accuracy: 0.9421 - val_loss: 0.2005\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9521 - loss: 0.1689 - val_accuracy: 0.9430 - val_loss: 0.2001\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9533 - loss: 0.1591 - val_accuracy: 0.9427 - val_loss: 0.1979\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9560 - loss: 0.1539 - val_accuracy: 0.9415 - val_loss: 0.2076\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9566 - loss: 0.1514 - val_accuracy: 0.9411 - val_loss: 0.1986\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9575 - loss: 0.1502 - val_accuracy: 0.9482 - val_loss: 0.1685\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9577 - loss: 0.1527 - val_accuracy: 0.9504 - val_loss: 0.1778\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9556 - loss: 0.1510 - val_accuracy: 0.9482 - val_loss: 0.1806\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9516 - loss: 0.1660 - val_accuracy: 0.9609 - val_loss: 0.1435\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9540 - loss: 0.1558 - val_accuracy: 0.9577 - val_loss: 0.1496\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9527 - loss: 0.1576 - val_accuracy: 0.9571 - val_loss: 0.1500\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9554 - loss: 0.1556 - val_accuracy: 0.9599 - val_loss: 0.1351\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9516 - loss: 0.1646 - val_accuracy: 0.9601 - val_loss: 0.1372\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9573 - loss: 0.1526 - val_accuracy: 0.9578 - val_loss: 0.1399\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Тип модели построения эмбеддингов: all_mpnet_base_v2\n",
      "Тип модели классификации: GRU_128\n",
      "Наличие предобработки текста: yes\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.8526 - loss: 0.5145 - val_accuracy: 0.9360 - val_loss: 0.2291\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9406 - loss: 0.2051 - val_accuracy: 0.9385 - val_loss: 0.2174\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9497 - loss: 0.1850 - val_accuracy: 0.9370 - val_loss: 0.2180\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9485 - loss: 0.1767 - val_accuracy: 0.9427 - val_loss: 0.2104\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9502 - loss: 0.1807 - val_accuracy: 0.9419 - val_loss: 0.2093\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9509 - loss: 0.1688 - val_accuracy: 0.9427 - val_loss: 0.2081\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9543 - loss: 0.1602 - val_accuracy: 0.9423 - val_loss: 0.2085\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9557 - loss: 0.1554 - val_accuracy: 0.9430 - val_loss: 0.2083\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9471 - loss: 0.1793 - val_accuracy: 0.9474 - val_loss: 0.1783\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9523 - loss: 0.1605 - val_accuracy: 0.9463 - val_loss: 0.1878\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9555 - loss: 0.1535 - val_accuracy: 0.9445 - val_loss: 0.1891\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9490 - loss: 0.1732 - val_accuracy: 0.9548 - val_loss: 0.1526\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9521 - loss: 0.1696 - val_accuracy: 0.9533 - val_loss: 0.1552\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9505 - loss: 0.1672 - val_accuracy: 0.9533 - val_loss: 0.1559\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9495 - loss: 0.1769 - val_accuracy: 0.9567 - val_loss: 0.1389\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.1804 - val_accuracy: 0.9556 - val_loss: 0.1428\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9521 - loss: 0.1690 - val_accuracy: 0.9559 - val_loss: 0.1445\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Тип модели построения эмбеддингов: all_mpnet_base_v2\n",
      "Тип модели классификации: GRU_256\n",
      "Наличие предобработки текста: no\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 20ms/step - accuracy: 0.8796 - loss: 0.4522 - val_accuracy: 0.9362 - val_loss: 0.2140\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.9430 - loss: 0.2028 - val_accuracy: 0.9373 - val_loss: 0.2120\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9465 - loss: 0.1821 - val_accuracy: 0.9413 - val_loss: 0.2021\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.9498 - loss: 0.1741 - val_accuracy: 0.9409 - val_loss: 0.2016\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.9544 - loss: 0.1580 - val_accuracy: 0.9421 - val_loss: 0.1983\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9576 - loss: 0.1509 - val_accuracy: 0.9425 - val_loss: 0.1989\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9539 - loss: 0.1559 - val_accuracy: 0.9421 - val_loss: 0.2014\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9508 - loss: 0.1690 - val_accuracy: 0.9493 - val_loss: 0.1757\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.9557 - loss: 0.1577 - val_accuracy: 0.9451 - val_loss: 0.1796\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.9561 - loss: 0.1490 - val_accuracy: 0.9464 - val_loss: 0.1830\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9495 - loss: 0.1749 - val_accuracy: 0.9582 - val_loss: 0.1459\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9500 - loss: 0.1658 - val_accuracy: 0.9605 - val_loss: 0.1471\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.9566 - loss: 0.1443 - val_accuracy: 0.9523 - val_loss: 0.1596\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9510 - loss: 0.1683 - val_accuracy: 0.9584 - val_loss: 0.1364\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.9526 - loss: 0.1573 - val_accuracy: 0.9603 - val_loss: 0.1409\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.9579 - loss: 0.1508 - val_accuracy: 0.9586 - val_loss: 0.1398\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Тип модели построения эмбеддингов: all_mpnet_base_v2\n",
      "Тип модели классификации: GRU_256\n",
      "Наличие предобработки текста: yes\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 20ms/step - accuracy: 0.8619 - loss: 0.4607 - val_accuracy: 0.9347 - val_loss: 0.2317\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9423 - loss: 0.2004 - val_accuracy: 0.9370 - val_loss: 0.2171\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.9438 - loss: 0.1918 - val_accuracy: 0.9392 - val_loss: 0.2129\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.9481 - loss: 0.1770 - val_accuracy: 0.9408 - val_loss: 0.2110\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9506 - loss: 0.1679 - val_accuracy: 0.9430 - val_loss: 0.2085\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9498 - loss: 0.1666 - val_accuracy: 0.9379 - val_loss: 0.2160\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.9528 - loss: 0.1606 - val_accuracy: 0.9415 - val_loss: 0.2094\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9515 - loss: 0.1717 - val_accuracy: 0.9480 - val_loss: 0.1793\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.9556 - loss: 0.1525 - val_accuracy: 0.9466 - val_loss: 0.1845\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9563 - loss: 0.1492 - val_accuracy: 0.9461 - val_loss: 0.1861\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9501 - loss: 0.1740 - val_accuracy: 0.9556 - val_loss: 0.1539\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.9478 - loss: 0.1681 - val_accuracy: 0.9525 - val_loss: 0.1566\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.9540 - loss: 0.1540 - val_accuracy: 0.9521 - val_loss: 0.1578\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9480 - loss: 0.1742 - val_accuracy: 0.9567 - val_loss: 0.1458\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.9511 - loss: 0.1674 - val_accuracy: 0.9565 - val_loss: 0.1413\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9578 - loss: 0.1525 - val_accuracy: 0.9550 - val_loss: 0.1466\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.9550 - loss: 0.1524 - val_accuracy: 0.9550 - val_loss: 0.1464\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Тип модели построения эмбеддингов: all_MiniLM_L6_v2\n",
      "Тип модели классификации: GRU_64\n",
      "Наличие предобработки текста: no\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8041 - loss: 0.6681 - val_accuracy: 0.9280 - val_loss: 0.2628\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9295 - loss: 0.2466 - val_accuracy: 0.9326 - val_loss: 0.2466\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9361 - loss: 0.2259 - val_accuracy: 0.9318 - val_loss: 0.2413\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9440 - loss: 0.2026 - val_accuracy: 0.9320 - val_loss: 0.2397\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9410 - loss: 0.2089 - val_accuracy: 0.9330 - val_loss: 0.2399\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9398 - loss: 0.2108 - val_accuracy: 0.9347 - val_loss: 0.2381\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9406 - loss: 0.1986 - val_accuracy: 0.9335 - val_loss: 0.2398\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9427 - loss: 0.1976 - val_accuracy: 0.9354 - val_loss: 0.2375\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9464 - loss: 0.1950 - val_accuracy: 0.9351 - val_loss: 0.2395\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9462 - loss: 0.1866 - val_accuracy: 0.9345 - val_loss: 0.2364\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9398 - loss: 0.2092 - val_accuracy: 0.9411 - val_loss: 0.1968\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9455 - loss: 0.1906 - val_accuracy: 0.9402 - val_loss: 0.2006\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9447 - loss: 0.1873 - val_accuracy: 0.9419 - val_loss: 0.2009\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9428 - loss: 0.2006 - val_accuracy: 0.9516 - val_loss: 0.1726\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9387 - loss: 0.2076 - val_accuracy: 0.9485 - val_loss: 0.1759\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9446 - loss: 0.1875 - val_accuracy: 0.9491 - val_loss: 0.1759\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9464 - loss: 0.1882 - val_accuracy: 0.9512 - val_loss: 0.1631\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9419 - loss: 0.2005 - val_accuracy: 0.9508 - val_loss: 0.1649\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9449 - loss: 0.1929 - val_accuracy: 0.9487 - val_loss: 0.1684\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Тип модели построения эмбеддингов: all_MiniLM_L6_v2\n",
      "Тип модели классификации: GRU_64\n",
      "Наличие предобработки текста: yes\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8065 - loss: 0.6547 - val_accuracy: 0.9263 - val_loss: 0.2690\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9260 - loss: 0.2530 - val_accuracy: 0.9311 - val_loss: 0.2536\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9308 - loss: 0.2367 - val_accuracy: 0.9297 - val_loss: 0.2484\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9352 - loss: 0.2190 - val_accuracy: 0.9313 - val_loss: 0.2460\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9358 - loss: 0.2102 - val_accuracy: 0.9341 - val_loss: 0.2445\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9386 - loss: 0.2077 - val_accuracy: 0.9318 - val_loss: 0.2431\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9351 - loss: 0.2106 - val_accuracy: 0.9332 - val_loss: 0.2422\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9412 - loss: 0.1974 - val_accuracy: 0.9333 - val_loss: 0.2445\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9417 - loss: 0.1986 - val_accuracy: 0.9333 - val_loss: 0.2411\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9421 - loss: 0.1954 - val_accuracy: 0.9332 - val_loss: 0.2416\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9396 - loss: 0.2074 - val_accuracy: 0.9385 - val_loss: 0.2080\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9411 - loss: 0.1939 - val_accuracy: 0.9358 - val_loss: 0.2127\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9431 - loss: 0.1912 - val_accuracy: 0.9366 - val_loss: 0.2130\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9416 - loss: 0.2019 - val_accuracy: 0.9445 - val_loss: 0.1827\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9353 - loss: 0.2122 - val_accuracy: 0.9427 - val_loss: 0.1847\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9437 - loss: 0.1914 - val_accuracy: 0.9421 - val_loss: 0.1869\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9373 - loss: 0.2154 - val_accuracy: 0.9447 - val_loss: 0.1702\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9402 - loss: 0.1995 - val_accuracy: 0.9427 - val_loss: 0.1741\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9378 - loss: 0.2071 - val_accuracy: 0.9432 - val_loss: 0.1725\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Тип модели построения эмбеддингов: all_MiniLM_L6_v2\n",
      "Тип модели классификации: GRU_128\n",
      "Наличие предобработки текста: no\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8388 - loss: 0.5875 - val_accuracy: 0.9301 - val_loss: 0.2501\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9310 - loss: 0.2365 - val_accuracy: 0.9305 - val_loss: 0.2439\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9350 - loss: 0.2241 - val_accuracy: 0.9343 - val_loss: 0.2405\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9411 - loss: 0.2080 - val_accuracy: 0.9333 - val_loss: 0.2399\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9454 - loss: 0.1925 - val_accuracy: 0.9343 - val_loss: 0.2382\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9433 - loss: 0.1998 - val_accuracy: 0.9345 - val_loss: 0.2399\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9461 - loss: 0.1921 - val_accuracy: 0.9339 - val_loss: 0.2368\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9457 - loss: 0.1890 - val_accuracy: 0.9332 - val_loss: 0.2429\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9475 - loss: 0.1805 - val_accuracy: 0.9337 - val_loss: 0.2384\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9442 - loss: 0.1942 - val_accuracy: 0.9423 - val_loss: 0.2017\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9430 - loss: 0.1998 - val_accuracy: 0.9419 - val_loss: 0.2086\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9466 - loss: 0.1872 - val_accuracy: 0.9404 - val_loss: 0.2097\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9413 - loss: 0.2023 - val_accuracy: 0.9506 - val_loss: 0.1772\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9430 - loss: 0.1975 - val_accuracy: 0.9476 - val_loss: 0.1815\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9447 - loss: 0.1885 - val_accuracy: 0.9482 - val_loss: 0.1820\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9445 - loss: 0.1996 - val_accuracy: 0.9499 - val_loss: 0.1682\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9444 - loss: 0.1934 - val_accuracy: 0.9482 - val_loss: 0.1724\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9438 - loss: 0.1990 - val_accuracy: 0.9464 - val_loss: 0.1720\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Тип модели построения эмбеддингов: all_MiniLM_L6_v2\n",
      "Тип модели классификации: GRU_128\n",
      "Наличие предобработки текста: yes\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8107 - loss: 0.5884 - val_accuracy: 0.9282 - val_loss: 0.2626\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9250 - loss: 0.2511 - val_accuracy: 0.9311 - val_loss: 0.2503\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9349 - loss: 0.2167 - val_accuracy: 0.9313 - val_loss: 0.2473\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9372 - loss: 0.2128 - val_accuracy: 0.9332 - val_loss: 0.2477\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9393 - loss: 0.2063 - val_accuracy: 0.9320 - val_loss: 0.2453\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9421 - loss: 0.2060 - val_accuracy: 0.9295 - val_loss: 0.2478\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9387 - loss: 0.1975 - val_accuracy: 0.9326 - val_loss: 0.2425\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9415 - loss: 0.1994 - val_accuracy: 0.9337 - val_loss: 0.2397\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9456 - loss: 0.1804 - val_accuracy: 0.9335 - val_loss: 0.2397\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9455 - loss: 0.1848 - val_accuracy: 0.9335 - val_loss: 0.2406\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9407 - loss: 0.2026 - val_accuracy: 0.9375 - val_loss: 0.2052\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9414 - loss: 0.1947 - val_accuracy: 0.9373 - val_loss: 0.2068\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9456 - loss: 0.1818 - val_accuracy: 0.9373 - val_loss: 0.2108\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9390 - loss: 0.2051 - val_accuracy: 0.9468 - val_loss: 0.1794\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9405 - loss: 0.1993 - val_accuracy: 0.9464 - val_loss: 0.1800\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9414 - loss: 0.1967 - val_accuracy: 0.9427 - val_loss: 0.1844\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9412 - loss: 0.2012 - val_accuracy: 0.9468 - val_loss: 0.1648\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9403 - loss: 0.2007 - val_accuracy: 0.9464 - val_loss: 0.1672\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9447 - loss: 0.1902 - val_accuracy: 0.9455 - val_loss: 0.1688\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Тип модели построения эмбеддингов: all_MiniLM_L6_v2\n",
      "Тип модели классификации: GRU_256\n",
      "Наличие предобработки текста: no\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.8522 - loss: 0.5301 - val_accuracy: 0.9290 - val_loss: 0.2469\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9334 - loss: 0.2277 - val_accuracy: 0.9320 - val_loss: 0.2452\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9408 - loss: 0.2097 - val_accuracy: 0.9333 - val_loss: 0.2388\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9426 - loss: 0.2041 - val_accuracy: 0.9314 - val_loss: 0.2434\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9456 - loss: 0.1966 - val_accuracy: 0.9345 - val_loss: 0.2405\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9395 - loss: 0.2138 - val_accuracy: 0.9375 - val_loss: 0.2189\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9424 - loss: 0.2064 - val_accuracy: 0.9339 - val_loss: 0.2311\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9454 - loss: 0.1868 - val_accuracy: 0.9347 - val_loss: 0.2257\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9402 - loss: 0.2103 - val_accuracy: 0.9463 - val_loss: 0.1884\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9454 - loss: 0.1887 - val_accuracy: 0.9455 - val_loss: 0.1940\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9430 - loss: 0.1944 - val_accuracy: 0.9423 - val_loss: 0.2003\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9399 - loss: 0.2074 - val_accuracy: 0.9459 - val_loss: 0.1830\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9380 - loss: 0.2120 - val_accuracy: 0.9455 - val_loss: 0.1852\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9419 - loss: 0.2048 - val_accuracy: 0.9436 - val_loss: 0.1853\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Тип модели построения эмбеддингов: all_MiniLM_L6_v2\n",
      "Тип модели классификации: GRU_256\n",
      "Наличие предобработки текста: yes\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.8300 - loss: 0.5311 - val_accuracy: 0.9282 - val_loss: 0.2592\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9349 - loss: 0.2255 - val_accuracy: 0.9316 - val_loss: 0.2485\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9349 - loss: 0.2185 - val_accuracy: 0.9299 - val_loss: 0.2483\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9400 - loss: 0.2057 - val_accuracy: 0.9322 - val_loss: 0.2463\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9353 - loss: 0.2094 - val_accuracy: 0.9309 - val_loss: 0.2431\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9405 - loss: 0.2034 - val_accuracy: 0.9333 - val_loss: 0.2424\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9432 - loss: 0.1868 - val_accuracy: 0.9307 - val_loss: 0.2420\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9442 - loss: 0.1852 - val_accuracy: 0.9328 - val_loss: 0.2452\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9439 - loss: 0.1788 - val_accuracy: 0.9322 - val_loss: 0.2395\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9452 - loss: 0.1798 - val_accuracy: 0.9339 - val_loss: 0.2394\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9401 - loss: 0.2011 - val_accuracy: 0.9423 - val_loss: 0.1945\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9449 - loss: 0.1898 - val_accuracy: 0.9409 - val_loss: 0.1988\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9468 - loss: 0.1758 - val_accuracy: 0.9398 - val_loss: 0.2006\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9393 - loss: 0.2014 - val_accuracy: 0.9474 - val_loss: 0.1674\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9442 - loss: 0.1856 - val_accuracy: 0.9464 - val_loss: 0.1727\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9438 - loss: 0.1870 - val_accuracy: 0.9463 - val_loss: 0.1763\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9392 - loss: 0.2055 - val_accuracy: 0.9520 - val_loss: 0.1563\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9447 - loss: 0.1866 - val_accuracy: 0.9455 - val_loss: 0.1600\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9470 - loss: 0.1777 - val_accuracy: 0.9483 - val_loss: 0.1610\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Тип модели построения эмбеддингов: Universal-sentence-encoder\n",
      "Тип модели классификации: GRU_64\n",
      "Наличие предобработки текста: no\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7882 - loss: 0.6500 - val_accuracy: 0.9303 - val_loss: 0.2539\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9346 - loss: 0.2319 - val_accuracy: 0.9322 - val_loss: 0.2415\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9346 - loss: 0.2229 - val_accuracy: 0.9322 - val_loss: 0.2391\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9398 - loss: 0.2062 - val_accuracy: 0.9347 - val_loss: 0.2353\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9414 - loss: 0.2020 - val_accuracy: 0.9335 - val_loss: 0.2361\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9384 - loss: 0.1995 - val_accuracy: 0.9358 - val_loss: 0.2370\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9428 - loss: 0.2067 - val_accuracy: 0.9368 - val_loss: 0.2147\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9416 - loss: 0.2042 - val_accuracy: 0.9332 - val_loss: 0.2189\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9416 - loss: 0.2012 - val_accuracy: 0.9351 - val_loss: 0.2212\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9386 - loss: 0.2133 - val_accuracy: 0.9425 - val_loss: 0.1935\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9388 - loss: 0.1991 - val_accuracy: 0.9402 - val_loss: 0.1939\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9426 - loss: 0.2025 - val_accuracy: 0.9383 - val_loss: 0.1969\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9373 - loss: 0.2095 - val_accuracy: 0.9461 - val_loss: 0.1863\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9393 - loss: 0.2059 - val_accuracy: 0.9436 - val_loss: 0.1853\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9373 - loss: 0.2095 - val_accuracy: 0.9438 - val_loss: 0.1870\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9437 - loss: 0.1872 - val_accuracy: 0.9445 - val_loss: 0.1876\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Тип модели построения эмбеддингов: Universal-sentence-encoder\n",
      "Тип модели классификации: GRU_64\n",
      "Наличие предобработки текста: yes\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7562 - loss: 0.6738 - val_accuracy: 0.9221 - val_loss: 0.2683\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.2524 - val_accuracy: 0.9286 - val_loss: 0.2573\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9356 - loss: 0.2227 - val_accuracy: 0.9284 - val_loss: 0.2501\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9359 - loss: 0.2121 - val_accuracy: 0.9311 - val_loss: 0.2491\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9382 - loss: 0.2129 - val_accuracy: 0.9284 - val_loss: 0.2491\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9368 - loss: 0.2128 - val_accuracy: 0.9271 - val_loss: 0.2510\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9375 - loss: 0.2025 - val_accuracy: 0.9309 - val_loss: 0.2465\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9454 - loss: 0.1875 - val_accuracy: 0.9305 - val_loss: 0.2460\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9419 - loss: 0.1924 - val_accuracy: 0.9295 - val_loss: 0.2470\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9452 - loss: 0.1831 - val_accuracy: 0.9326 - val_loss: 0.2459\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9397 - loss: 0.2062 - val_accuracy: 0.9423 - val_loss: 0.1946\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9410 - loss: 0.1982 - val_accuracy: 0.9394 - val_loss: 0.1998\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9427 - loss: 0.1929 - val_accuracy: 0.9383 - val_loss: 0.2055\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9389 - loss: 0.2049 - val_accuracy: 0.9449 - val_loss: 0.1748\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9381 - loss: 0.1987 - val_accuracy: 0.9459 - val_loss: 0.1782\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9450 - loss: 0.1933 - val_accuracy: 0.9434 - val_loss: 0.1809\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9361 - loss: 0.2161 - val_accuracy: 0.9474 - val_loss: 0.1652\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9402 - loss: 0.2069 - val_accuracy: 0.9438 - val_loss: 0.1711\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9449 - loss: 0.1900 - val_accuracy: 0.9417 - val_loss: 0.1760\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Тип модели построения эмбеддингов: Universal-sentence-encoder\n",
      "Тип модели классификации: GRU_128\n",
      "Наличие предобработки текста: no\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8292 - loss: 0.5775 - val_accuracy: 0.9297 - val_loss: 0.2481\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9319 - loss: 0.2326 - val_accuracy: 0.9309 - val_loss: 0.2441\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9350 - loss: 0.2172 - val_accuracy: 0.9337 - val_loss: 0.2399\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9401 - loss: 0.2044 - val_accuracy: 0.9354 - val_loss: 0.2368\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9413 - loss: 0.1951 - val_accuracy: 0.9349 - val_loss: 0.2387\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9399 - loss: 0.2000 - val_accuracy: 0.9337 - val_loss: 0.2345\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9412 - loss: 0.1899 - val_accuracy: 0.9337 - val_loss: 0.2378\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9446 - loss: 0.1912 - val_accuracy: 0.9347 - val_loss: 0.2355\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9415 - loss: 0.2032 - val_accuracy: 0.9398 - val_loss: 0.2031\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9444 - loss: 0.1894 - val_accuracy: 0.9375 - val_loss: 0.2095\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9436 - loss: 0.1869 - val_accuracy: 0.9354 - val_loss: 0.2142\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9409 - loss: 0.1961 - val_accuracy: 0.9442 - val_loss: 0.1813\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9417 - loss: 0.1974 - val_accuracy: 0.9432 - val_loss: 0.1832\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9446 - loss: 0.1882 - val_accuracy: 0.9413 - val_loss: 0.1856\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9460 - loss: 0.1935 - val_accuracy: 0.9495 - val_loss: 0.1684\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9412 - loss: 0.1980 - val_accuracy: 0.9482 - val_loss: 0.1726\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9488 - loss: 0.1848 - val_accuracy: 0.9444 - val_loss: 0.1751\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Тип модели построения эмбеддингов: Universal-sentence-encoder\n",
      "Тип модели классификации: GRU_128\n",
      "Наличие предобработки текста: yes\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8051 - loss: 0.5930 - val_accuracy: 0.9250 - val_loss: 0.2628\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9282 - loss: 0.2386 - val_accuracy: 0.9288 - val_loss: 0.2494\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9365 - loss: 0.2170 - val_accuracy: 0.9288 - val_loss: 0.2493\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9349 - loss: 0.2120 - val_accuracy: 0.9314 - val_loss: 0.2489\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9319 - loss: 0.2187 - val_accuracy: 0.9259 - val_loss: 0.2527\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9383 - loss: 0.1981 - val_accuracy: 0.9314 - val_loss: 0.2496\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9364 - loss: 0.2145 - val_accuracy: 0.9351 - val_loss: 0.2156\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9365 - loss: 0.2163 - val_accuracy: 0.9339 - val_loss: 0.2217\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9381 - loss: 0.2060 - val_accuracy: 0.9314 - val_loss: 0.2336\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9343 - loss: 0.2197 - val_accuracy: 0.9421 - val_loss: 0.1935\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9379 - loss: 0.2105 - val_accuracy: 0.9394 - val_loss: 0.1990\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9357 - loss: 0.2111 - val_accuracy: 0.9402 - val_loss: 0.1989\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9358 - loss: 0.2220 - val_accuracy: 0.9421 - val_loss: 0.1829\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9389 - loss: 0.2106 - val_accuracy: 0.9396 - val_loss: 0.1856\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9402 - loss: 0.1995 - val_accuracy: 0.9381 - val_loss: 0.1904\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Тип модели построения эмбеддингов: Universal-sentence-encoder\n",
      "Тип модели классификации: GRU_256\n",
      "Наличие предобработки текста: no\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.8295 - loss: 0.5197 - val_accuracy: 0.9328 - val_loss: 0.2449\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9331 - loss: 0.2318 - val_accuracy: 0.9339 - val_loss: 0.2402\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9375 - loss: 0.2095 - val_accuracy: 0.9339 - val_loss: 0.2399\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9427 - loss: 0.1945 - val_accuracy: 0.9347 - val_loss: 0.2383\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9416 - loss: 0.1973 - val_accuracy: 0.9371 - val_loss: 0.2371\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9409 - loss: 0.1911 - val_accuracy: 0.9356 - val_loss: 0.2342\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9437 - loss: 0.1830 - val_accuracy: 0.9337 - val_loss: 0.2377\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9454 - loss: 0.1829 - val_accuracy: 0.9362 - val_loss: 0.2360\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9406 - loss: 0.1970 - val_accuracy: 0.9394 - val_loss: 0.2016\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9418 - loss: 0.1875 - val_accuracy: 0.9375 - val_loss: 0.2126\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9473 - loss: 0.1775 - val_accuracy: 0.9379 - val_loss: 0.2104\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9433 - loss: 0.1956 - val_accuracy: 0.9447 - val_loss: 0.1803\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9460 - loss: 0.1815 - val_accuracy: 0.9415 - val_loss: 0.1825\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9476 - loss: 0.1803 - val_accuracy: 0.9423 - val_loss: 0.1853\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9435 - loss: 0.1916 - val_accuracy: 0.9485 - val_loss: 0.1658\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9442 - loss: 0.1907 - val_accuracy: 0.9489 - val_loss: 0.1703\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9482 - loss: 0.1852 - val_accuracy: 0.9453 - val_loss: 0.1748\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Тип модели построения эмбеддингов: Universal-sentence-encoder\n",
      "Тип модели классификации: GRU_256\n",
      "Наличие предобработки текста: yes\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.8374 - loss: 0.5364 - val_accuracy: 0.9258 - val_loss: 0.2614\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9294 - loss: 0.2336 - val_accuracy: 0.9299 - val_loss: 0.2509\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9359 - loss: 0.2059 - val_accuracy: 0.9256 - val_loss: 0.2526\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9392 - loss: 0.2026 - val_accuracy: 0.9275 - val_loss: 0.2479\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9402 - loss: 0.2015 - val_accuracy: 0.9261 - val_loss: 0.2488\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9398 - loss: 0.1962 - val_accuracy: 0.9322 - val_loss: 0.2460\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9381 - loss: 0.2055 - val_accuracy: 0.9328 - val_loss: 0.2489\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9470 - loss: 0.1789 - val_accuracy: 0.9307 - val_loss: 0.2539\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9364 - loss: 0.2112 - val_accuracy: 0.9383 - val_loss: 0.2092\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9407 - loss: 0.2004 - val_accuracy: 0.9383 - val_loss: 0.2104\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9450 - loss: 0.1880 - val_accuracy: 0.9345 - val_loss: 0.2198\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9416 - loss: 0.2015 - val_accuracy: 0.9425 - val_loss: 0.1853\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9427 - loss: 0.1888 - val_accuracy: 0.9447 - val_loss: 0.1867\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9424 - loss: 0.1921 - val_accuracy: 0.9406 - val_loss: 0.1908\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9368 - loss: 0.2120 - val_accuracy: 0.9457 - val_loss: 0.1706\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9411 - loss: 0.2012 - val_accuracy: 0.9432 - val_loss: 0.1748\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9408 - loss: 0.1979 - val_accuracy: 0.9442 - val_loss: 0.1781\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "embeddings_models_list = []\n",
    "classification_models = []\n",
    "preprocessing_types = []\n",
    "acc_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "for i in range(1, 4):\n",
    "    for gru_size in [64, 128, 256]:\n",
    "        for prep_type in ['_text', '_prep_text']:\n",
    "            print(f'Тип модели построения эмбеддингов: {embeddings_models[i-1]}')\n",
    "            print(f'Тип модели классификации: GRU_{gru_size}')\n",
    "\n",
    "            embeddings_models_list.append(embeddings_models[i-1])\n",
    "            classification_models.append(f'GRU_{gru_size}')\n",
    "\n",
    "            X = np.array(df[f'{i}{prep_type}'].to_list())\n",
    "            labels = np.array(df['Label'])\n",
    "\n",
    "            prep_type_label = 'yes' if prep_type == '_prep_text' else 'no'\n",
    "            print(f'Наличие предобработки текста: {prep_type_label}')\n",
    "            preprocessing_types.append(prep_type_label)\n",
    "\n",
    "            X_train_val, X_test, y_train_val, y_test = train_test_split(X, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "            model = Sequential()\n",
    "            model.add(Bidirectional(GRU(gru_size, input_shape=(1, X_train_val.shape[1]))))\n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(4, activation='softmax'))  \n",
    "\n",
    "            model.compile(loss='categorical_crossentropy',\n",
    "                          optimizer='adam',\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "            y_train_val_categorical = to_categorical(y_train_val, num_classes=4)\n",
    "            y_test_categorical = to_categorical(y_test, num_classes=4)\n",
    "\n",
    "            n_splits = 4\n",
    "            kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "            for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X_train_val, y_train_val)):\n",
    "                print(f\"Training fold {fold_idx + 1}/{n_splits}\")\n",
    "\n",
    "                X_train = X_train_val[train_idx]\n",
    "                y_train = y_train_val_categorical[train_idx]\n",
    "                X_val = X_train_val[val_idx]\n",
    "                y_val = y_train_val_categorical[val_idx]\n",
    "\n",
    "                X_train_gru = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "                X_val_gru = np.reshape(X_val, (X_val.shape[0], 1, X_val.shape[1]))\n",
    "\n",
    "                early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "                model.fit(X_train_gru, y_train, validation_data=(X_val_gru, y_val), epochs=10, callbacks=[early_stopping])\n",
    "\n",
    "            # Оценка модели на тестовой выборке\n",
    "            X_test_gru = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "            y_pred_categorical = model.predict(X_test_gru)\n",
    "            y_pred = y_pred_categorical.argmax(axis=1)\n",
    "\n",
    "            # Вычисление метрик\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, average='macro')\n",
    "            recall = recall_score(y_test, y_pred, average='macro')\n",
    "            f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "            acc_list.append(accuracy)\n",
    "            precision_list.append(precision)\n",
    "            recall_list.append(recall)\n",
    "            f1_list.append(f1)\n",
    "\n",
    "gru_results = pd.DataFrame({\n",
    "    'embeddings_model': embeddings_models_list,\n",
    "    'classification_model': classification_models,\n",
    "    'preprocessing_has': preprocessing_types,\n",
    "    'accuracy': acc_list,\n",
    "    'precision_macro': precision_list,\n",
    "    'recall_macro': recall_list,\n",
    "    'f1_macro': f1_list\n",
    "})\n",
    "\n",
    "gru_results.to_csv('gru_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings_model</th>\n",
       "      <th>classification_model</th>\n",
       "      <th>preprocessing_has</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all_mpnet_base_v2</td>\n",
       "      <td>GRU_64</td>\n",
       "      <td>no</td>\n",
       "      <td>0.950817</td>\n",
       "      <td>0.951614</td>\n",
       "      <td>0.948338</td>\n",
       "      <td>0.949903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all_mpnet_base_v2</td>\n",
       "      <td>GRU_64</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.949487</td>\n",
       "      <td>0.949299</td>\n",
       "      <td>0.948073</td>\n",
       "      <td>0.948645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all_mpnet_base_v2</td>\n",
       "      <td>GRU_128</td>\n",
       "      <td>no</td>\n",
       "      <td>0.948348</td>\n",
       "      <td>0.950776</td>\n",
       "      <td>0.944785</td>\n",
       "      <td>0.947608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all_mpnet_base_v2</td>\n",
       "      <td>GRU_128</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.948538</td>\n",
       "      <td>0.949117</td>\n",
       "      <td>0.946375</td>\n",
       "      <td>0.947703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>all_mpnet_base_v2</td>\n",
       "      <td>GRU_256</td>\n",
       "      <td>no</td>\n",
       "      <td>0.950247</td>\n",
       "      <td>0.951382</td>\n",
       "      <td>0.947506</td>\n",
       "      <td>0.949357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>all_mpnet_base_v2</td>\n",
       "      <td>GRU_256</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.948728</td>\n",
       "      <td>0.949921</td>\n",
       "      <td>0.945715</td>\n",
       "      <td>0.947753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>all_MiniLM_L6_v2</td>\n",
       "      <td>GRU_64</td>\n",
       "      <td>no</td>\n",
       "      <td>0.942651</td>\n",
       "      <td>0.943359</td>\n",
       "      <td>0.941018</td>\n",
       "      <td>0.941978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>all_MiniLM_L6_v2</td>\n",
       "      <td>GRU_64</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.938283</td>\n",
       "      <td>0.937284</td>\n",
       "      <td>0.937866</td>\n",
       "      <td>0.937493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>all_MiniLM_L6_v2</td>\n",
       "      <td>GRU_128</td>\n",
       "      <td>no</td>\n",
       "      <td>0.941701</td>\n",
       "      <td>0.944137</td>\n",
       "      <td>0.938008</td>\n",
       "      <td>0.940793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>all_MiniLM_L6_v2</td>\n",
       "      <td>GRU_128</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.942081</td>\n",
       "      <td>0.944377</td>\n",
       "      <td>0.938077</td>\n",
       "      <td>0.941039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>all_MiniLM_L6_v2</td>\n",
       "      <td>GRU_256</td>\n",
       "      <td>no</td>\n",
       "      <td>0.943600</td>\n",
       "      <td>0.944883</td>\n",
       "      <td>0.940971</td>\n",
       "      <td>0.942841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>all_MiniLM_L6_v2</td>\n",
       "      <td>GRU_256</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.942841</td>\n",
       "      <td>0.943027</td>\n",
       "      <td>0.940738</td>\n",
       "      <td>0.941843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Universal-sentence-encoder</td>\n",
       "      <td>GRU_64</td>\n",
       "      <td>no</td>\n",
       "      <td>0.940372</td>\n",
       "      <td>0.941107</td>\n",
       "      <td>0.939327</td>\n",
       "      <td>0.940130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Universal-sentence-encoder</td>\n",
       "      <td>GRU_64</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.937714</td>\n",
       "      <td>0.938726</td>\n",
       "      <td>0.936169</td>\n",
       "      <td>0.937364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Universal-sentence-encoder</td>\n",
       "      <td>GRU_128</td>\n",
       "      <td>no</td>\n",
       "      <td>0.939233</td>\n",
       "      <td>0.938898</td>\n",
       "      <td>0.939156</td>\n",
       "      <td>0.938981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Universal-sentence-encoder</td>\n",
       "      <td>GRU_128</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.933916</td>\n",
       "      <td>0.932251</td>\n",
       "      <td>0.934482</td>\n",
       "      <td>0.933313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Universal-sentence-encoder</td>\n",
       "      <td>GRU_256</td>\n",
       "      <td>no</td>\n",
       "      <td>0.939613</td>\n",
       "      <td>0.941723</td>\n",
       "      <td>0.936919</td>\n",
       "      <td>0.939195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Universal-sentence-encoder</td>\n",
       "      <td>GRU_256</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.936194</td>\n",
       "      <td>0.937861</td>\n",
       "      <td>0.933895</td>\n",
       "      <td>0.935757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              embeddings_model classification_model preprocessing_has  \\\n",
       "0            all_mpnet_base_v2               GRU_64                no   \n",
       "1            all_mpnet_base_v2               GRU_64               yes   \n",
       "2            all_mpnet_base_v2              GRU_128                no   \n",
       "3            all_mpnet_base_v2              GRU_128               yes   \n",
       "4            all_mpnet_base_v2              GRU_256                no   \n",
       "5            all_mpnet_base_v2              GRU_256               yes   \n",
       "6             all_MiniLM_L6_v2               GRU_64                no   \n",
       "7             all_MiniLM_L6_v2               GRU_64               yes   \n",
       "8             all_MiniLM_L6_v2              GRU_128                no   \n",
       "9             all_MiniLM_L6_v2              GRU_128               yes   \n",
       "10            all_MiniLM_L6_v2              GRU_256                no   \n",
       "11            all_MiniLM_L6_v2              GRU_256               yes   \n",
       "12  Universal-sentence-encoder               GRU_64                no   \n",
       "13  Universal-sentence-encoder               GRU_64               yes   \n",
       "14  Universal-sentence-encoder              GRU_128                no   \n",
       "15  Universal-sentence-encoder              GRU_128               yes   \n",
       "16  Universal-sentence-encoder              GRU_256                no   \n",
       "17  Universal-sentence-encoder              GRU_256               yes   \n",
       "\n",
       "    accuracy  precision_macro  recall_macro  f1_macro  \n",
       "0   0.950817         0.951614      0.948338  0.949903  \n",
       "1   0.949487         0.949299      0.948073  0.948645  \n",
       "2   0.948348         0.950776      0.944785  0.947608  \n",
       "3   0.948538         0.949117      0.946375  0.947703  \n",
       "4   0.950247         0.951382      0.947506  0.949357  \n",
       "5   0.948728         0.949921      0.945715  0.947753  \n",
       "6   0.942651         0.943359      0.941018  0.941978  \n",
       "7   0.938283         0.937284      0.937866  0.937493  \n",
       "8   0.941701         0.944137      0.938008  0.940793  \n",
       "9   0.942081         0.944377      0.938077  0.941039  \n",
       "10  0.943600         0.944883      0.940971  0.942841  \n",
       "11  0.942841         0.943027      0.940738  0.941843  \n",
       "12  0.940372         0.941107      0.939327  0.940130  \n",
       "13  0.937714         0.938726      0.936169  0.937364  \n",
       "14  0.939233         0.938898      0.939156  0.938981  \n",
       "15  0.933916         0.932251      0.934482  0.933313  \n",
       "16  0.939613         0.941723      0.936919  0.939195  \n",
       "17  0.936194         0.937861      0.933895  0.935757  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сравнение моделей Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип модели построения эмбеддингов: all_mpnet_base_v2\n",
      "Тип модели классификации: Perceptron_64\n",
      "Наличие предобработки текста: no\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8057 - loss: 0.6565 - val_accuracy: 0.9349 - val_loss: 0.2351\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.9339 - loss: 0.2431 - val_accuracy: 0.9383 - val_loss: 0.2164\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9444 - loss: 0.2030 - val_accuracy: 0.9394 - val_loss: 0.2054\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.9479 - loss: 0.1942 - val_accuracy: 0.9394 - val_loss: 0.2010\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.9510 - loss: 0.1822 - val_accuracy: 0.9396 - val_loss: 0.1993\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 977us/step - accuracy: 0.9512 - loss: 0.1774 - val_accuracy: 0.9425 - val_loss: 0.1924\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.9532 - loss: 0.1698 - val_accuracy: 0.9432 - val_loss: 0.1920\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.9560 - loss: 0.1667 - val_accuracy: 0.9440 - val_loss: 0.1918\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.9556 - loss: 0.1535 - val_accuracy: 0.9442 - val_loss: 0.1948\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.9575 - loss: 0.1514 - val_accuracy: 0.9466 - val_loss: 0.1898\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9557 - loss: 0.1599 - val_accuracy: 0.9571 - val_loss: 0.1428\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 983us/step - accuracy: 0.9557 - loss: 0.1522 - val_accuracy: 0.9559 - val_loss: 0.1461\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - accuracy: 0.9547 - loss: 0.1469 - val_accuracy: 0.9540 - val_loss: 0.1496\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9542 - loss: 0.1694 - val_accuracy: 0.9656 - val_loss: 0.1198\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9587 - loss: 0.1507 - val_accuracy: 0.9633 - val_loss: 0.1239\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9546 - loss: 0.1525 - val_accuracy: 0.9641 - val_loss: 0.1244\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9544 - loss: 0.1656 - val_accuracy: 0.9666 - val_loss: 0.1122\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9565 - loss: 0.1568 - val_accuracy: 0.9652 - val_loss: 0.1155\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.9582 - loss: 0.1451 - val_accuracy: 0.9645 - val_loss: 0.1181\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step\n",
      "Тип модели построения эмбеддингов: all_mpnet_base_v2\n",
      "Тип модели классификации: Perceptron_64\n",
      "Наличие предобработки текста: yes\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8383 - loss: 0.6518 - val_accuracy: 0.9333 - val_loss: 0.2424\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.9356 - loss: 0.2414 - val_accuracy: 0.9385 - val_loss: 0.2247\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.9367 - loss: 0.2253 - val_accuracy: 0.9392 - val_loss: 0.2163\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.9436 - loss: 0.2021 - val_accuracy: 0.9417 - val_loss: 0.2125\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.9438 - loss: 0.1939 - val_accuracy: 0.9406 - val_loss: 0.2106\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.9445 - loss: 0.1950 - val_accuracy: 0.9421 - val_loss: 0.2065\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.9504 - loss: 0.1761 - val_accuracy: 0.9417 - val_loss: 0.2049\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.9498 - loss: 0.1690 - val_accuracy: 0.9445 - val_loss: 0.2015\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9482 - loss: 0.1781 - val_accuracy: 0.9444 - val_loss: 0.2023\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.9505 - loss: 0.1682 - val_accuracy: 0.9455 - val_loss: 0.2032\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9529 - loss: 0.1735 - val_accuracy: 0.9525 - val_loss: 0.1624\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.9513 - loss: 0.1717 - val_accuracy: 0.9497 - val_loss: 0.1675\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.9550 - loss: 0.1657 - val_accuracy: 0.9502 - val_loss: 0.1695\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9511 - loss: 0.1762 - val_accuracy: 0.9588 - val_loss: 0.1417\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.9522 - loss: 0.1762 - val_accuracy: 0.9578 - val_loss: 0.1410\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.9527 - loss: 0.1650 - val_accuracy: 0.9571 - val_loss: 0.1429\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.9524 - loss: 0.1609 - val_accuracy: 0.9558 - val_loss: 0.1441\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9513 - loss: 0.1657 - val_accuracy: 0.9633 - val_loss: 0.1247\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.9523 - loss: 0.1735 - val_accuracy: 0.9618 - val_loss: 0.1279\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9544 - loss: 0.1601 - val_accuracy: 0.9618 - val_loss: 0.1298\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step\n",
      "Тип модели построения эмбеддингов: all_mpnet_base_v2\n",
      "Тип модели классификации: Perceptron_128\n",
      "Наличие предобработки текста: no\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8443 - loss: 0.5653 - val_accuracy: 0.9347 - val_loss: 0.2226\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9398 - loss: 0.2156 - val_accuracy: 0.9387 - val_loss: 0.2081\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9467 - loss: 0.1804 - val_accuracy: 0.9406 - val_loss: 0.1979\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9488 - loss: 0.1835 - val_accuracy: 0.9423 - val_loss: 0.1946\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9536 - loss: 0.1662 - val_accuracy: 0.9438 - val_loss: 0.1915\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9539 - loss: 0.1605 - val_accuracy: 0.9445 - val_loss: 0.1880\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9561 - loss: 0.1464 - val_accuracy: 0.9459 - val_loss: 0.1874\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9586 - loss: 0.1434 - val_accuracy: 0.9464 - val_loss: 0.1876\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9621 - loss: 0.1321 - val_accuracy: 0.9483 - val_loss: 0.1827\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9657 - loss: 0.1232 - val_accuracy: 0.9468 - val_loss: 0.1855\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9594 - loss: 0.1368 - val_accuracy: 0.9607 - val_loss: 0.1279\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9598 - loss: 0.1365 - val_accuracy: 0.9590 - val_loss: 0.1339\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9643 - loss: 0.1226 - val_accuracy: 0.9596 - val_loss: 0.1343\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9598 - loss: 0.1352 - val_accuracy: 0.9685 - val_loss: 0.1093\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9634 - loss: 0.1304 - val_accuracy: 0.9677 - val_loss: 0.1122\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9617 - loss: 0.1292 - val_accuracy: 0.9677 - val_loss: 0.1103\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9584 - loss: 0.1396 - val_accuracy: 0.9717 - val_loss: 0.0985\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9605 - loss: 0.1326 - val_accuracy: 0.9709 - val_loss: 0.1000\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9639 - loss: 0.1221 - val_accuracy: 0.9685 - val_loss: 0.1052\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step\n",
      "Тип модели построения эмбеддингов: all_mpnet_base_v2\n",
      "Тип модели классификации: Perceptron_128\n",
      "Наличие предобработки текста: yes\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8153 - loss: 0.5847 - val_accuracy: 0.9354 - val_loss: 0.2321\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9355 - loss: 0.2238 - val_accuracy: 0.9381 - val_loss: 0.2197\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9417 - loss: 0.2104 - val_accuracy: 0.9396 - val_loss: 0.2096\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9473 - loss: 0.1916 - val_accuracy: 0.9419 - val_loss: 0.2067\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9512 - loss: 0.1732 - val_accuracy: 0.9421 - val_loss: 0.2009\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9528 - loss: 0.1609 - val_accuracy: 0.9444 - val_loss: 0.1983\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9506 - loss: 0.1680 - val_accuracy: 0.9472 - val_loss: 0.2000\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9545 - loss: 0.1505 - val_accuracy: 0.9476 - val_loss: 0.1966\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9561 - loss: 0.1512 - val_accuracy: 0.9453 - val_loss: 0.1972\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9623 - loss: 0.1320 - val_accuracy: 0.9464 - val_loss: 0.1950\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9565 - loss: 0.1461 - val_accuracy: 0.9597 - val_loss: 0.1308\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9617 - loss: 0.1392 - val_accuracy: 0.9580 - val_loss: 0.1365\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9567 - loss: 0.1402 - val_accuracy: 0.9578 - val_loss: 0.1396\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9577 - loss: 0.1443 - val_accuracy: 0.9679 - val_loss: 0.1095\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9564 - loss: 0.1473 - val_accuracy: 0.9668 - val_loss: 0.1138\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9647 - loss: 0.1281 - val_accuracy: 0.9656 - val_loss: 0.1147\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9577 - loss: 0.1490 - val_accuracy: 0.9698 - val_loss: 0.0997\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9602 - loss: 0.1347 - val_accuracy: 0.9675 - val_loss: 0.1042\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9652 - loss: 0.1240 - val_accuracy: 0.9692 - val_loss: 0.1062\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step\n",
      "Тип модели построения эмбеддингов: all_mpnet_base_v2\n",
      "Тип модели классификации: Perceptron_256\n",
      "Наличие предобработки текста: no\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8626 - loss: 0.5032 - val_accuracy: 0.9377 - val_loss: 0.2159\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9399 - loss: 0.2112 - val_accuracy: 0.9392 - val_loss: 0.2032\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9465 - loss: 0.1776 - val_accuracy: 0.9423 - val_loss: 0.1955\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9529 - loss: 0.1578 - val_accuracy: 0.9455 - val_loss: 0.1892\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9540 - loss: 0.1524 - val_accuracy: 0.9455 - val_loss: 0.1860\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9590 - loss: 0.1423 - val_accuracy: 0.9466 - val_loss: 0.1827\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9584 - loss: 0.1431 - val_accuracy: 0.9480 - val_loss: 0.1818\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9612 - loss: 0.1224 - val_accuracy: 0.9478 - val_loss: 0.1853\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9674 - loss: 0.1145 - val_accuracy: 0.9474 - val_loss: 0.1810\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9695 - loss: 0.1055 - val_accuracy: 0.9489 - val_loss: 0.1840\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9638 - loss: 0.1312 - val_accuracy: 0.9666 - val_loss: 0.1089\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9685 - loss: 0.1081 - val_accuracy: 0.9643 - val_loss: 0.1160\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9699 - loss: 0.1028 - val_accuracy: 0.9649 - val_loss: 0.1166\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9674 - loss: 0.1116 - val_accuracy: 0.9744 - val_loss: 0.0913\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9697 - loss: 0.1039 - val_accuracy: 0.9732 - val_loss: 0.0943\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9692 - loss: 0.1014 - val_accuracy: 0.9734 - val_loss: 0.0933\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9675 - loss: 0.1172 - val_accuracy: 0.9772 - val_loss: 0.0788\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9679 - loss: 0.1063 - val_accuracy: 0.9768 - val_loss: 0.0817\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9702 - loss: 0.1021 - val_accuracy: 0.9759 - val_loss: 0.0823\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step\n",
      "Тип модели построения эмбеддингов: all_mpnet_base_v2\n",
      "Тип модели классификации: Perceptron_256\n",
      "Наличие предобработки текста: yes\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8512 - loss: 0.5091 - val_accuracy: 0.9377 - val_loss: 0.2272\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9379 - loss: 0.2184 - val_accuracy: 0.9408 - val_loss: 0.2157\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9444 - loss: 0.1882 - val_accuracy: 0.9415 - val_loss: 0.2079\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9495 - loss: 0.1729 - val_accuracy: 0.9428 - val_loss: 0.2028\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9505 - loss: 0.1713 - val_accuracy: 0.9440 - val_loss: 0.2011\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9534 - loss: 0.1558 - val_accuracy: 0.9461 - val_loss: 0.1979\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9574 - loss: 0.1385 - val_accuracy: 0.9480 - val_loss: 0.1956\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9616 - loss: 0.1298 - val_accuracy: 0.9489 - val_loss: 0.1928\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9645 - loss: 0.1183 - val_accuracy: 0.9474 - val_loss: 0.1920\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9667 - loss: 0.1131 - val_accuracy: 0.9474 - val_loss: 0.1952\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9658 - loss: 0.1340 - val_accuracy: 0.9630 - val_loss: 0.1190\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9628 - loss: 0.1243 - val_accuracy: 0.9645 - val_loss: 0.1230\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9649 - loss: 0.1203 - val_accuracy: 0.9607 - val_loss: 0.1250\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9625 - loss: 0.1319 - val_accuracy: 0.9677 - val_loss: 0.0996\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9622 - loss: 0.1334 - val_accuracy: 0.9679 - val_loss: 0.1055\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9674 - loss: 0.1106 - val_accuracy: 0.9675 - val_loss: 0.1044\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9627 - loss: 0.1205 - val_accuracy: 0.9761 - val_loss: 0.0864\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9659 - loss: 0.1193 - val_accuracy: 0.9742 - val_loss: 0.0888\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9661 - loss: 0.1113 - val_accuracy: 0.9711 - val_loss: 0.0951\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step\n",
      "Тип модели построения эмбеддингов: all_mpnet_base_v2\n",
      "Тип модели классификации: Perceptron_512\n",
      "Наличие предобработки текста: no\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8771 - loss: 0.4353 - val_accuracy: 0.9364 - val_loss: 0.2154\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9444 - loss: 0.1957 - val_accuracy: 0.9421 - val_loss: 0.1956\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9524 - loss: 0.1665 - val_accuracy: 0.9440 - val_loss: 0.1905\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9559 - loss: 0.1478 - val_accuracy: 0.9457 - val_loss: 0.1881\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9593 - loss: 0.1337 - val_accuracy: 0.9480 - val_loss: 0.1830\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9652 - loss: 0.1207 - val_accuracy: 0.9487 - val_loss: 0.1804\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9698 - loss: 0.1053 - val_accuracy: 0.9478 - val_loss: 0.1790\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9711 - loss: 0.0955 - val_accuracy: 0.9497 - val_loss: 0.1804\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9747 - loss: 0.0860 - val_accuracy: 0.9508 - val_loss: 0.1809\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9636 - loss: 0.1258 - val_accuracy: 0.9639 - val_loss: 0.1121\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9668 - loss: 0.1097 - val_accuracy: 0.9635 - val_loss: 0.1130\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9719 - loss: 0.0934 - val_accuracy: 0.9643 - val_loss: 0.1187\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9651 - loss: 0.1135 - val_accuracy: 0.9776 - val_loss: 0.0826\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9712 - loss: 0.1043 - val_accuracy: 0.9753 - val_loss: 0.0886\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9747 - loss: 0.0847 - val_accuracy: 0.9734 - val_loss: 0.0924\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9691 - loss: 0.1061 - val_accuracy: 0.9806 - val_loss: 0.0716\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9724 - loss: 0.0933 - val_accuracy: 0.9770 - val_loss: 0.0741\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9785 - loss: 0.0770 - val_accuracy: 0.9768 - val_loss: 0.0787\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step\n",
      "Тип модели построения эмбеддингов: all_mpnet_base_v2\n",
      "Тип модели классификации: Perceptron_512\n",
      "Наличие предобработки текста: yes\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8638 - loss: 0.4516 - val_accuracy: 0.9404 - val_loss: 0.2204\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9387 - loss: 0.2088 - val_accuracy: 0.9408 - val_loss: 0.2155\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9476 - loss: 0.1760 - val_accuracy: 0.9449 - val_loss: 0.2007\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9529 - loss: 0.1622 - val_accuracy: 0.9459 - val_loss: 0.1979\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9549 - loss: 0.1527 - val_accuracy: 0.9472 - val_loss: 0.1953\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9567 - loss: 0.1412 - val_accuracy: 0.9474 - val_loss: 0.1928\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9652 - loss: 0.1173 - val_accuracy: 0.9502 - val_loss: 0.1920\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9699 - loss: 0.1048 - val_accuracy: 0.9510 - val_loss: 0.1892\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9707 - loss: 0.1020 - val_accuracy: 0.9470 - val_loss: 0.1948\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9742 - loss: 0.0840 - val_accuracy: 0.9502 - val_loss: 0.1938\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9654 - loss: 0.1346 - val_accuracy: 0.9662 - val_loss: 0.1061\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9689 - loss: 0.1045 - val_accuracy: 0.9651 - val_loss: 0.1109\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9737 - loss: 0.0887 - val_accuracy: 0.9660 - val_loss: 0.1114\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.1241 - val_accuracy: 0.9765 - val_loss: 0.0866\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9703 - loss: 0.1060 - val_accuracy: 0.9734 - val_loss: 0.0877\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9726 - loss: 0.0873 - val_accuracy: 0.9728 - val_loss: 0.0894\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9658 - loss: 0.1121 - val_accuracy: 0.9799 - val_loss: 0.0741\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9698 - loss: 0.1004 - val_accuracy: 0.9763 - val_loss: 0.0773\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9770 - loss: 0.0858 - val_accuracy: 0.9770 - val_loss: 0.0820\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step\n",
      "Тип модели построения эмбеддингов: all_MiniLM_L6_v2\n",
      "Тип модели классификации: Perceptron_64\n",
      "Наличие предобработки текста: no\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7637 - loss: 0.7505 - val_accuracy: 0.9265 - val_loss: 0.2670\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.9197 - loss: 0.2786 - val_accuracy: 0.9280 - val_loss: 0.2495\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.9317 - loss: 0.2498 - val_accuracy: 0.9330 - val_loss: 0.2404\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.9325 - loss: 0.2398 - val_accuracy: 0.9332 - val_loss: 0.2374\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.9369 - loss: 0.2191 - val_accuracy: 0.9322 - val_loss: 0.2346\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.9400 - loss: 0.2188 - val_accuracy: 0.9343 - val_loss: 0.2335\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.9427 - loss: 0.2005 - val_accuracy: 0.9351 - val_loss: 0.2306\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.9444 - loss: 0.1985 - val_accuracy: 0.9352 - val_loss: 0.2304\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.9433 - loss: 0.1981 - val_accuracy: 0.9345 - val_loss: 0.2299\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.9447 - loss: 0.1932 - val_accuracy: 0.9345 - val_loss: 0.2280\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9439 - loss: 0.2074 - val_accuracy: 0.9483 - val_loss: 0.1782\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.9474 - loss: 0.1862 - val_accuracy: 0.9487 - val_loss: 0.1810\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.9490 - loss: 0.1886 - val_accuracy: 0.9480 - val_loss: 0.1837\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.9427 - loss: 0.1992 - val_accuracy: 0.9546 - val_loss: 0.1560\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.9435 - loss: 0.1969 - val_accuracy: 0.9544 - val_loss: 0.1571\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.9455 - loss: 0.1961 - val_accuracy: 0.9539 - val_loss: 0.1583\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9443 - loss: 0.2053 - val_accuracy: 0.9569 - val_loss: 0.1448\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.9466 - loss: 0.1928 - val_accuracy: 0.9540 - val_loss: 0.1498\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.9481 - loss: 0.1891 - val_accuracy: 0.9544 - val_loss: 0.1496\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step\n",
      "Тип модели построения эмбеддингов: all_MiniLM_L6_v2\n",
      "Тип модели классификации: Perceptron_64\n",
      "Наличие предобработки текста: yes\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7428 - loss: 0.7628 - val_accuracy: 0.9240 - val_loss: 0.2780\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9197 - loss: 0.2862 - val_accuracy: 0.9256 - val_loss: 0.2610\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9270 - loss: 0.2664 - val_accuracy: 0.9295 - val_loss: 0.2510\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9255 - loss: 0.2544 - val_accuracy: 0.9320 - val_loss: 0.2469\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9319 - loss: 0.2349 - val_accuracy: 0.9324 - val_loss: 0.2427\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9371 - loss: 0.2165 - val_accuracy: 0.9335 - val_loss: 0.2371\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.9365 - loss: 0.2187 - val_accuracy: 0.9339 - val_loss: 0.2371\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.9405 - loss: 0.2089 - val_accuracy: 0.9341 - val_loss: 0.2365\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.9383 - loss: 0.2137 - val_accuracy: 0.9356 - val_loss: 0.2348\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 986us/step - accuracy: 0.9382 - loss: 0.2105 - val_accuracy: 0.9362 - val_loss: 0.2355\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 975us/step - accuracy: 0.9407 - loss: 0.2037 - val_accuracy: 0.9425 - val_loss: 0.1932\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.9400 - loss: 0.2099 - val_accuracy: 0.9425 - val_loss: 0.1962\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.9442 - loss: 0.1981 - val_accuracy: 0.9411 - val_loss: 0.1992\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - accuracy: 0.9404 - loss: 0.2140 - val_accuracy: 0.9491 - val_loss: 0.1679\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.9425 - loss: 0.2058 - val_accuracy: 0.9504 - val_loss: 0.1692\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.9426 - loss: 0.2101 - val_accuracy: 0.9478 - val_loss: 0.1716\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9390 - loss: 0.2133 - val_accuracy: 0.9482 - val_loss: 0.1532\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 0.9401 - loss: 0.2098 - val_accuracy: 0.9491 - val_loss: 0.1565\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.9407 - loss: 0.2117 - val_accuracy: 0.9485 - val_loss: 0.1591\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step\n",
      "Тип модели построения эмбеддингов: all_MiniLM_L6_v2\n",
      "Тип модели классификации: Perceptron_128\n",
      "Наличие предобработки текста: no\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8124 - loss: 0.6498 - val_accuracy: 0.9261 - val_loss: 0.2583\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9257 - loss: 0.2502 - val_accuracy: 0.9313 - val_loss: 0.2416\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9379 - loss: 0.2217 - val_accuracy: 0.9339 - val_loss: 0.2358\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 976us/step - accuracy: 0.9401 - loss: 0.2096 - val_accuracy: 0.9335 - val_loss: 0.2307\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - accuracy: 0.9432 - loss: 0.2036 - val_accuracy: 0.9349 - val_loss: 0.2287\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9432 - loss: 0.1998 - val_accuracy: 0.9324 - val_loss: 0.2318\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9444 - loss: 0.1845 - val_accuracy: 0.9352 - val_loss: 0.2263\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 0.9515 - loss: 0.1757 - val_accuracy: 0.9347 - val_loss: 0.2289\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9465 - loss: 0.1775 - val_accuracy: 0.9362 - val_loss: 0.2224\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9577 - loss: 0.1501 - val_accuracy: 0.9381 - val_loss: 0.2200\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9493 - loss: 0.1803 - val_accuracy: 0.9548 - val_loss: 0.1578\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9551 - loss: 0.1591 - val_accuracy: 0.9539 - val_loss: 0.1613\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 986us/step - accuracy: 0.9546 - loss: 0.1610 - val_accuracy: 0.9535 - val_loss: 0.1643\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9507 - loss: 0.1767 - val_accuracy: 0.9616 - val_loss: 0.1332\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9529 - loss: 0.1740 - val_accuracy: 0.9590 - val_loss: 0.1377\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9532 - loss: 0.1620 - val_accuracy: 0.9594 - val_loss: 0.1376\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9504 - loss: 0.1708 - val_accuracy: 0.9647 - val_loss: 0.1218\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.9565 - loss: 0.1552 - val_accuracy: 0.9656 - val_loss: 0.1242\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9566 - loss: 0.1519 - val_accuracy: 0.9639 - val_loss: 0.1266\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step\n",
      "Тип модели построения эмбеддингов: all_MiniLM_L6_v2\n",
      "Тип модели классификации: Perceptron_128\n",
      "Наличие предобработки текста: yes\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7797 - loss: 0.6624 - val_accuracy: 0.9273 - val_loss: 0.2681\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9227 - loss: 0.2702 - val_accuracy: 0.9288 - val_loss: 0.2525\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9314 - loss: 0.2311 - val_accuracy: 0.9301 - val_loss: 0.2468\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9309 - loss: 0.2303 - val_accuracy: 0.9343 - val_loss: 0.2398\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 992us/step - accuracy: 0.9396 - loss: 0.2073 - val_accuracy: 0.9332 - val_loss: 0.2386\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9432 - loss: 0.1937 - val_accuracy: 0.9343 - val_loss: 0.2331\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.9438 - loss: 0.1891 - val_accuracy: 0.9358 - val_loss: 0.2305\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9473 - loss: 0.1806 - val_accuracy: 0.9366 - val_loss: 0.2311\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9448 - loss: 0.1822 - val_accuracy: 0.9370 - val_loss: 0.2331\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9418 - loss: 0.1959 - val_accuracy: 0.9461 - val_loss: 0.1862\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.9451 - loss: 0.1886 - val_accuracy: 0.9440 - val_loss: 0.1906\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.9479 - loss: 0.1764 - val_accuracy: 0.9445 - val_loss: 0.1902\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9443 - loss: 0.1911 - val_accuracy: 0.9504 - val_loss: 0.1629\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9459 - loss: 0.1852 - val_accuracy: 0.9510 - val_loss: 0.1649\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9447 - loss: 0.1895 - val_accuracy: 0.9483 - val_loss: 0.1653\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9437 - loss: 0.1949 - val_accuracy: 0.9559 - val_loss: 0.1432\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9461 - loss: 0.1870 - val_accuracy: 0.9529 - val_loss: 0.1457\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9475 - loss: 0.1806 - val_accuracy: 0.9540 - val_loss: 0.1462\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step\n",
      "Тип модели построения эмбеддингов: all_MiniLM_L6_v2\n",
      "Тип модели классификации: Perceptron_256\n",
      "Наличие предобработки текста: no\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8410 - loss: 0.5851 - val_accuracy: 0.9280 - val_loss: 0.2522\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9310 - loss: 0.2320 - val_accuracy: 0.9339 - val_loss: 0.2381\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9398 - loss: 0.2076 - val_accuracy: 0.9330 - val_loss: 0.2325\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9402 - loss: 0.2030 - val_accuracy: 0.9358 - val_loss: 0.2271\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9486 - loss: 0.1754 - val_accuracy: 0.9385 - val_loss: 0.2239\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9497 - loss: 0.1764 - val_accuracy: 0.9375 - val_loss: 0.2210\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9576 - loss: 0.1569 - val_accuracy: 0.9387 - val_loss: 0.2197\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9566 - loss: 0.1549 - val_accuracy: 0.9404 - val_loss: 0.2158\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9572 - loss: 0.1445 - val_accuracy: 0.9406 - val_loss: 0.2164\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9594 - loss: 0.1473 - val_accuracy: 0.9411 - val_loss: 0.2170\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9539 - loss: 0.1714 - val_accuracy: 0.9567 - val_loss: 0.1489\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9574 - loss: 0.1518 - val_accuracy: 0.9561 - val_loss: 0.1521\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9601 - loss: 0.1435 - val_accuracy: 0.9554 - val_loss: 0.1578\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9554 - loss: 0.1518 - val_accuracy: 0.9652 - val_loss: 0.1245\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9587 - loss: 0.1437 - val_accuracy: 0.9637 - val_loss: 0.1269\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9616 - loss: 0.1369 - val_accuracy: 0.9645 - val_loss: 0.1275\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9556 - loss: 0.1535 - val_accuracy: 0.9683 - val_loss: 0.1101\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9592 - loss: 0.1395 - val_accuracy: 0.9685 - val_loss: 0.1151\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9606 - loss: 0.1366 - val_accuracy: 0.9668 - val_loss: 0.1147\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step\n",
      "Тип модели построения эмбеддингов: all_MiniLM_L6_v2\n",
      "Тип модели классификации: Perceptron_256\n",
      "Наличие предобработки текста: yes\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7951 - loss: 0.5880 - val_accuracy: 0.9290 - val_loss: 0.2603\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9286 - loss: 0.2412 - val_accuracy: 0.9324 - val_loss: 0.2459\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9358 - loss: 0.2203 - val_accuracy: 0.9332 - val_loss: 0.2381\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9359 - loss: 0.2078 - val_accuracy: 0.9351 - val_loss: 0.2348\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9433 - loss: 0.1952 - val_accuracy: 0.9345 - val_loss: 0.2314\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9431 - loss: 0.1798 - val_accuracy: 0.9345 - val_loss: 0.2298\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9478 - loss: 0.1741 - val_accuracy: 0.9370 - val_loss: 0.2279\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9502 - loss: 0.1739 - val_accuracy: 0.9373 - val_loss: 0.2243\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9560 - loss: 0.1493 - val_accuracy: 0.9398 - val_loss: 0.2283\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9568 - loss: 0.1447 - val_accuracy: 0.9406 - val_loss: 0.2239\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9514 - loss: 0.1716 - val_accuracy: 0.9577 - val_loss: 0.1419\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9540 - loss: 0.1589 - val_accuracy: 0.9525 - val_loss: 0.1515\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9590 - loss: 0.1493 - val_accuracy: 0.9563 - val_loss: 0.1486\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9501 - loss: 0.1650 - val_accuracy: 0.9664 - val_loss: 0.1212\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9556 - loss: 0.1535 - val_accuracy: 0.9643 - val_loss: 0.1221\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9619 - loss: 0.1321 - val_accuracy: 0.9654 - val_loss: 0.1231\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9544 - loss: 0.1522 - val_accuracy: 0.9690 - val_loss: 0.1040\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9571 - loss: 0.1503 - val_accuracy: 0.9685 - val_loss: 0.1068\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9621 - loss: 0.1302 - val_accuracy: 0.9702 - val_loss: 0.1052\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step\n",
      "Тип модели построения эмбеддингов: all_MiniLM_L6_v2\n",
      "Тип модели классификации: Perceptron_512\n",
      "Наличие предобработки текста: no\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8507 - loss: 0.5177 - val_accuracy: 0.9297 - val_loss: 0.2439\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9387 - loss: 0.2194 - val_accuracy: 0.9351 - val_loss: 0.2345\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9421 - loss: 0.1996 - val_accuracy: 0.9354 - val_loss: 0.2265\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9464 - loss: 0.1821 - val_accuracy: 0.9373 - val_loss: 0.2236\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9538 - loss: 0.1632 - val_accuracy: 0.9366 - val_loss: 0.2202\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9589 - loss: 0.1434 - val_accuracy: 0.9411 - val_loss: 0.2148\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9572 - loss: 0.1500 - val_accuracy: 0.9421 - val_loss: 0.2176\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9613 - loss: 0.1272 - val_accuracy: 0.9430 - val_loss: 0.2100\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9660 - loss: 0.1181 - val_accuracy: 0.9427 - val_loss: 0.2094\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9710 - loss: 0.1033 - val_accuracy: 0.9440 - val_loss: 0.2080\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9661 - loss: 0.1295 - val_accuracy: 0.9728 - val_loss: 0.0996\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9696 - loss: 0.1086 - val_accuracy: 0.9692 - val_loss: 0.1040\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9715 - loss: 0.1028 - val_accuracy: 0.9687 - val_loss: 0.1075\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9675 - loss: 0.1230 - val_accuracy: 0.9778 - val_loss: 0.0788\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9692 - loss: 0.1117 - val_accuracy: 0.9766 - val_loss: 0.0821\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9732 - loss: 0.0912 - val_accuracy: 0.9763 - val_loss: 0.0859\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9672 - loss: 0.1178 - val_accuracy: 0.9842 - val_loss: 0.0679\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9710 - loss: 0.1012 - val_accuracy: 0.9827 - val_loss: 0.0722\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9765 - loss: 0.0845 - val_accuracy: 0.9776 - val_loss: 0.0756\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "Тип модели построения эмбеддингов: all_MiniLM_L6_v2\n",
      "Тип модели классификации: Perceptron_512\n",
      "Наличие предобработки текста: yes\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8464 - loss: 0.5200 - val_accuracy: 0.9295 - val_loss: 0.2565\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9346 - loss: 0.2241 - val_accuracy: 0.9335 - val_loss: 0.2425\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9375 - loss: 0.2067 - val_accuracy: 0.9309 - val_loss: 0.2387\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9428 - loss: 0.1866 - val_accuracy: 0.9351 - val_loss: 0.2326\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9451 - loss: 0.1800 - val_accuracy: 0.9379 - val_loss: 0.2258\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9479 - loss: 0.1677 - val_accuracy: 0.9408 - val_loss: 0.2267\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9540 - loss: 0.1457 - val_accuracy: 0.9390 - val_loss: 0.2216\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9579 - loss: 0.1411 - val_accuracy: 0.9408 - val_loss: 0.2196\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9645 - loss: 0.1244 - val_accuracy: 0.9406 - val_loss: 0.2180\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9666 - loss: 0.1116 - val_accuracy: 0.9432 - val_loss: 0.2163\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9599 - loss: 0.1443 - val_accuracy: 0.9649 - val_loss: 0.1168\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9668 - loss: 0.1189 - val_accuracy: 0.9660 - val_loss: 0.1186\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9698 - loss: 0.1085 - val_accuracy: 0.9645 - val_loss: 0.1233\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9622 - loss: 0.1367 - val_accuracy: 0.9734 - val_loss: 0.0906\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9653 - loss: 0.1163 - val_accuracy: 0.9719 - val_loss: 0.0935\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9700 - loss: 0.1030 - val_accuracy: 0.9708 - val_loss: 0.0971\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9630 - loss: 0.1228 - val_accuracy: 0.9801 - val_loss: 0.0752\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9672 - loss: 0.1096 - val_accuracy: 0.9791 - val_loss: 0.0800\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9708 - loss: 0.0964 - val_accuracy: 0.9759 - val_loss: 0.0784\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n",
      "Тип модели построения эмбеддингов: Universal-sentence-encoder\n",
      "Тип модели классификации: Perceptron_64\n",
      "Наличие предобработки текста: no\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7553 - loss: 0.7498 - val_accuracy: 0.9276 - val_loss: 0.2651\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9223 - loss: 0.2734 - val_accuracy: 0.9318 - val_loss: 0.2429\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.9320 - loss: 0.2391 - val_accuracy: 0.9330 - val_loss: 0.2355\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.9340 - loss: 0.2329 - val_accuracy: 0.9358 - val_loss: 0.2334\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9360 - loss: 0.2167 - val_accuracy: 0.9366 - val_loss: 0.2291\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9444 - loss: 0.2004 - val_accuracy: 0.9370 - val_loss: 0.2281\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.9432 - loss: 0.1981 - val_accuracy: 0.9366 - val_loss: 0.2271\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9417 - loss: 0.2016 - val_accuracy: 0.9362 - val_loss: 0.2270\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.9469 - loss: 0.1847 - val_accuracy: 0.9368 - val_loss: 0.2242\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.9445 - loss: 0.1939 - val_accuracy: 0.9370 - val_loss: 0.2247\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9425 - loss: 0.2022 - val_accuracy: 0.9472 - val_loss: 0.1777\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9461 - loss: 0.1893 - val_accuracy: 0.9461 - val_loss: 0.1819\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9495 - loss: 0.1816 - val_accuracy: 0.9442 - val_loss: 0.1878\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9474 - loss: 0.1925 - val_accuracy: 0.9516 - val_loss: 0.1577\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9424 - loss: 0.1939 - val_accuracy: 0.9506 - val_loss: 0.1604\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9448 - loss: 0.1990 - val_accuracy: 0.9493 - val_loss: 0.1636\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9448 - loss: 0.1956 - val_accuracy: 0.9554 - val_loss: 0.1467\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9446 - loss: 0.1914 - val_accuracy: 0.9539 - val_loss: 0.1502\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.9462 - loss: 0.1891 - val_accuracy: 0.9523 - val_loss: 0.1522\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step\n",
      "Тип модели построения эмбеддингов: Universal-sentence-encoder\n",
      "Тип модели классификации: Perceptron_64\n",
      "Наличие предобработки текста: yes\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7374 - loss: 0.7703 - val_accuracy: 0.9212 - val_loss: 0.2805\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.9176 - loss: 0.2914 - val_accuracy: 0.9250 - val_loss: 0.2564\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.9280 - loss: 0.2549 - val_accuracy: 0.9261 - val_loss: 0.2498\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.2518 - val_accuracy: 0.9294 - val_loss: 0.2458\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.9324 - loss: 0.2302 - val_accuracy: 0.9297 - val_loss: 0.2427\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.9345 - loss: 0.2216 - val_accuracy: 0.9311 - val_loss: 0.2398\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - accuracy: 0.9396 - loss: 0.2085 - val_accuracy: 0.9320 - val_loss: 0.2375\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 981us/step - accuracy: 0.9363 - loss: 0.2104 - val_accuracy: 0.9328 - val_loss: 0.2391\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.9406 - loss: 0.2117 - val_accuracy: 0.9328 - val_loss: 0.2373\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.9392 - loss: 0.2046 - val_accuracy: 0.9345 - val_loss: 0.2370\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9411 - loss: 0.2201 - val_accuracy: 0.9468 - val_loss: 0.1778\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - accuracy: 0.9394 - loss: 0.2157 - val_accuracy: 0.9459 - val_loss: 0.1817\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.9462 - loss: 0.1954 - val_accuracy: 0.9445 - val_loss: 0.1848\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9406 - loss: 0.1969 - val_accuracy: 0.9533 - val_loss: 0.1588\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 0.9440 - loss: 0.1913 - val_accuracy: 0.9514 - val_loss: 0.1614\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - accuracy: 0.9451 - loss: 0.1986 - val_accuracy: 0.9501 - val_loss: 0.1632\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9407 - loss: 0.2125 - val_accuracy: 0.9525 - val_loss: 0.1487\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9449 - loss: 0.1945 - val_accuracy: 0.9525 - val_loss: 0.1521\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.9485 - loss: 0.1859 - val_accuracy: 0.9512 - val_loss: 0.1542\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step\n",
      "Тип модели построения эмбеддингов: Universal-sentence-encoder\n",
      "Тип модели классификации: Perceptron_128\n",
      "Наличие предобработки текста: no\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7929 - loss: 0.6472 - val_accuracy: 0.9311 - val_loss: 0.2537\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9286 - loss: 0.2469 - val_accuracy: 0.9309 - val_loss: 0.2396\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9374 - loss: 0.2188 - val_accuracy: 0.9341 - val_loss: 0.2325\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9384 - loss: 0.2105 - val_accuracy: 0.9368 - val_loss: 0.2298\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9457 - loss: 0.1931 - val_accuracy: 0.9370 - val_loss: 0.2275\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9431 - loss: 0.1858 - val_accuracy: 0.9383 - val_loss: 0.2231\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9450 - loss: 0.1810 - val_accuracy: 0.9406 - val_loss: 0.2209\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9502 - loss: 0.1715 - val_accuracy: 0.9392 - val_loss: 0.2218\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9513 - loss: 0.1695 - val_accuracy: 0.9408 - val_loss: 0.2197\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9559 - loss: 0.1491 - val_accuracy: 0.9404 - val_loss: 0.2207\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9487 - loss: 0.1789 - val_accuracy: 0.9521 - val_loss: 0.1611\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9532 - loss: 0.1655 - val_accuracy: 0.9518 - val_loss: 0.1648\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9570 - loss: 0.1597 - val_accuracy: 0.9504 - val_loss: 0.1708\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9466 - loss: 0.1895 - val_accuracy: 0.9565 - val_loss: 0.1378\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9528 - loss: 0.1634 - val_accuracy: 0.9542 - val_loss: 0.1411\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9550 - loss: 0.1649 - val_accuracy: 0.9548 - val_loss: 0.1464\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9490 - loss: 0.1752 - val_accuracy: 0.9618 - val_loss: 0.1276\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9523 - loss: 0.1628 - val_accuracy: 0.9609 - val_loss: 0.1303\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9552 - loss: 0.1552 - val_accuracy: 0.9599 - val_loss: 0.1312\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step\n",
      "Тип модели построения эмбеддингов: Universal-sentence-encoder\n",
      "Тип модели классификации: Perceptron_128\n",
      "Наличие предобработки текста: yes\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8045 - loss: 0.6718 - val_accuracy: 0.9235 - val_loss: 0.2698\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9247 - loss: 0.2577 - val_accuracy: 0.9295 - val_loss: 0.2511\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9312 - loss: 0.2372 - val_accuracy: 0.9305 - val_loss: 0.2431\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9372 - loss: 0.2133 - val_accuracy: 0.9294 - val_loss: 0.2395\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9451 - loss: 0.1907 - val_accuracy: 0.9337 - val_loss: 0.2382\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9430 - loss: 0.1861 - val_accuracy: 0.9316 - val_loss: 0.2327\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9477 - loss: 0.1845 - val_accuracy: 0.9333 - val_loss: 0.2333\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9433 - loss: 0.1860 - val_accuracy: 0.9352 - val_loss: 0.2353\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9381 - loss: 0.2103 - val_accuracy: 0.9430 - val_loss: 0.1863\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9448 - loss: 0.1887 - val_accuracy: 0.9445 - val_loss: 0.1880\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9491 - loss: 0.1790 - val_accuracy: 0.9440 - val_loss: 0.1914\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9404 - loss: 0.1976 - val_accuracy: 0.9510 - val_loss: 0.1632\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9470 - loss: 0.1846 - val_accuracy: 0.9504 - val_loss: 0.1650\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9463 - loss: 0.1799 - val_accuracy: 0.9491 - val_loss: 0.1655\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9456 - loss: 0.1993 - val_accuracy: 0.9546 - val_loss: 0.1502\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9469 - loss: 0.1829 - val_accuracy: 0.9516 - val_loss: 0.1537\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9484 - loss: 0.1846 - val_accuracy: 0.9506 - val_loss: 0.1552\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step\n",
      "Тип модели построения эмбеддингов: Universal-sentence-encoder\n",
      "Тип модели классификации: Perceptron_256\n",
      "Наличие предобработки текста: no\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8309 - loss: 0.5716 - val_accuracy: 0.9297 - val_loss: 0.2481\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9332 - loss: 0.2258 - val_accuracy: 0.9328 - val_loss: 0.2358\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9372 - loss: 0.2062 - val_accuracy: 0.9377 - val_loss: 0.2265\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9431 - loss: 0.1931 - val_accuracy: 0.9364 - val_loss: 0.2240\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9457 - loss: 0.1852 - val_accuracy: 0.9402 - val_loss: 0.2232\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9495 - loss: 0.1705 - val_accuracy: 0.9408 - val_loss: 0.2179\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9551 - loss: 0.1553 - val_accuracy: 0.9408 - val_loss: 0.2195\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9593 - loss: 0.1370 - val_accuracy: 0.9406 - val_loss: 0.2128\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9589 - loss: 0.1385 - val_accuracy: 0.9425 - val_loss: 0.2153\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9591 - loss: 0.1362 - val_accuracy: 0.9442 - val_loss: 0.2178\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9550 - loss: 0.1643 - val_accuracy: 0.9578 - val_loss: 0.1448\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9577 - loss: 0.1503 - val_accuracy: 0.9573 - val_loss: 0.1499\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9630 - loss: 0.1368 - val_accuracy: 0.9573 - val_loss: 0.1537\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9557 - loss: 0.1573 - val_accuracy: 0.9613 - val_loss: 0.1237\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9587 - loss: 0.1485 - val_accuracy: 0.9596 - val_loss: 0.1253\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9619 - loss: 0.1298 - val_accuracy: 0.9611 - val_loss: 0.1272\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9534 - loss: 0.1601 - val_accuracy: 0.9696 - val_loss: 0.1059\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9596 - loss: 0.1394 - val_accuracy: 0.9702 - val_loss: 0.1094\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9631 - loss: 0.1282 - val_accuracy: 0.9681 - val_loss: 0.1110\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step\n",
      "Тип модели построения эмбеддингов: Universal-sentence-encoder\n",
      "Тип модели классификации: Perceptron_256\n",
      "Наличие предобработки текста: yes\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8190 - loss: 0.5883 - val_accuracy: 0.9242 - val_loss: 0.2635\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9316 - loss: 0.2314 - val_accuracy: 0.9284 - val_loss: 0.2488\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9347 - loss: 0.2146 - val_accuracy: 0.9303 - val_loss: 0.2408\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9382 - loss: 0.2002 - val_accuracy: 0.9322 - val_loss: 0.2351\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9430 - loss: 0.1926 - val_accuracy: 0.9339 - val_loss: 0.2330\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9456 - loss: 0.1823 - val_accuracy: 0.9356 - val_loss: 0.2322\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9492 - loss: 0.1707 - val_accuracy: 0.9351 - val_loss: 0.2309\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9552 - loss: 0.1491 - val_accuracy: 0.9389 - val_loss: 0.2269\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9571 - loss: 0.1469 - val_accuracy: 0.9358 - val_loss: 0.2303\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9576 - loss: 0.1410 - val_accuracy: 0.9425 - val_loss: 0.2268\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9564 - loss: 0.1559 - val_accuracy: 0.9626 - val_loss: 0.1325\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9556 - loss: 0.1482 - val_accuracy: 0.9603 - val_loss: 0.1384\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9641 - loss: 0.1315 - val_accuracy: 0.9603 - val_loss: 0.1399\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9557 - loss: 0.1472 - val_accuracy: 0.9660 - val_loss: 0.1098\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9582 - loss: 0.1498 - val_accuracy: 0.9666 - val_loss: 0.1113\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9627 - loss: 0.1323 - val_accuracy: 0.9639 - val_loss: 0.1167\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9562 - loss: 0.1546 - val_accuracy: 0.9728 - val_loss: 0.0982\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9620 - loss: 0.1262 - val_accuracy: 0.9715 - val_loss: 0.1017\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9670 - loss: 0.1230 - val_accuracy: 0.9713 - val_loss: 0.1029\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step\n",
      "Тип модели построения эмбеддингов: Universal-sentence-encoder\n",
      "Тип модели классификации: Perceptron_512\n",
      "Наличие предобработки текста: no\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8542 - loss: 0.5173 - val_accuracy: 0.9299 - val_loss: 0.2446\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9357 - loss: 0.2197 - val_accuracy: 0.9364 - val_loss: 0.2320\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9437 - loss: 0.1924 - val_accuracy: 0.9375 - val_loss: 0.2247\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9424 - loss: 0.1873 - val_accuracy: 0.9417 - val_loss: 0.2189\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9529 - loss: 0.1657 - val_accuracy: 0.9404 - val_loss: 0.2194\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9530 - loss: 0.1534 - val_accuracy: 0.9419 - val_loss: 0.2168\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9602 - loss: 0.1326 - val_accuracy: 0.9428 - val_loss: 0.2126\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9651 - loss: 0.1175 - val_accuracy: 0.9427 - val_loss: 0.2117\n",
      "Epoch 9/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9687 - loss: 0.1105 - val_accuracy: 0.9432 - val_loss: 0.2122\n",
      "Epoch 10/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9709 - loss: 0.0974 - val_accuracy: 0.9451 - val_loss: 0.2155\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9624 - loss: 0.1440 - val_accuracy: 0.9641 - val_loss: 0.1215\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9667 - loss: 0.1177 - val_accuracy: 0.9582 - val_loss: 0.1336\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9672 - loss: 0.1096 - val_accuracy: 0.9622 - val_loss: 0.1344\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9587 - loss: 0.1390 - val_accuracy: 0.9708 - val_loss: 0.1003\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9660 - loss: 0.1237 - val_accuracy: 0.9696 - val_loss: 0.1005\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9692 - loss: 0.1101 - val_accuracy: 0.9696 - val_loss: 0.1031\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9623 - loss: 0.1271 - val_accuracy: 0.9753 - val_loss: 0.0819\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9681 - loss: 0.1102 - val_accuracy: 0.9757 - val_loss: 0.0857\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9737 - loss: 0.0940 - val_accuracy: 0.9727 - val_loss: 0.0864\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step\n",
      "Тип модели построения эмбеддингов: Universal-sentence-encoder\n",
      "Тип модели классификации: Perceptron_512\n",
      "Наличие предобработки текста: yes\n",
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8218 - loss: 0.5330 - val_accuracy: 0.9269 - val_loss: 0.2542\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9284 - loss: 0.2343 - val_accuracy: 0.9301 - val_loss: 0.2433\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9355 - loss: 0.2174 - val_accuracy: 0.9324 - val_loss: 0.2412\n",
      "Epoch 4/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9437 - loss: 0.1911 - val_accuracy: 0.9347 - val_loss: 0.2370\n",
      "Epoch 5/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9486 - loss: 0.1730 - val_accuracy: 0.9377 - val_loss: 0.2293\n",
      "Epoch 6/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9540 - loss: 0.1524 - val_accuracy: 0.9389 - val_loss: 0.2240\n",
      "Epoch 7/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9560 - loss: 0.1422 - val_accuracy: 0.9387 - val_loss: 0.2288\n",
      "Epoch 8/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9631 - loss: 0.1294 - val_accuracy: 0.9402 - val_loss: 0.2248\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9517 - loss: 0.1688 - val_accuracy: 0.9540 - val_loss: 0.1553\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9546 - loss: 0.1535 - val_accuracy: 0.9540 - val_loss: 0.1557\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9593 - loss: 0.1382 - val_accuracy: 0.9527 - val_loss: 0.1590\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9561 - loss: 0.1649 - val_accuracy: 0.9647 - val_loss: 0.1240\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9555 - loss: 0.1542 - val_accuracy: 0.9618 - val_loss: 0.1294\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9628 - loss: 0.1290 - val_accuracy: 0.9615 - val_loss: 0.1279\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9518 - loss: 0.1673 - val_accuracy: 0.9683 - val_loss: 0.1074\n",
      "Epoch 2/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9630 - loss: 0.1255 - val_accuracy: 0.9671 - val_loss: 0.1110\n",
      "Epoch 3/10\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9640 - loss: 0.1198 - val_accuracy: 0.9647 - val_loss: 0.1153\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "embeddings_models_list = []\n",
    "classification_models = []\n",
    "preprocessing_types = []\n",
    "acc_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "num_classes = 4  \n",
    "\n",
    "for i in range(1, 4):\n",
    "    for layer_size in [64, 128, 256, 512]:\n",
    "        for prep_type in ['_text', '_prep_text']:\n",
    "            print(f'Тип модели построения эмбеддингов: {embeddings_models[i-1]}')\n",
    "            print(f'Тип модели классификации: Perceptron_{layer_size}')\n",
    "\n",
    "            embeddings_models_list.append(embeddings_models[i-1])\n",
    "            classification_models.append(f'Perceptron_{layer_size}')\n",
    "\n",
    "            X = np.array(df[f'{i}{prep_type}'].to_list())\n",
    "            labels = np.array(df['Label'])\n",
    "\n",
    "            prep_type_label = 'yes' if prep_type == '_prep_text' else 'no'\n",
    "            print(f'Наличие предобработки текста: {prep_type_label}')\n",
    "            preprocessing_types.append(prep_type_label)\n",
    "\n",
    "            X_train_val, X_test, y_train_val, y_test = train_test_split(X, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "            n_features = len(X_train_val[0])\n",
    "\n",
    "            model = Sequential()\n",
    "            model.add(Dense(layer_size, input_shape=(n_features,)))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(4, activation='softmax'))  \n",
    "\n",
    "            model.compile(loss='categorical_crossentropy',\n",
    "                            optimizer='adam',\n",
    "                            metrics=['accuracy'])\n",
    "\n",
    "            y_train_val_categorical = to_categorical(y_train_val, num_classes=num_classes)\n",
    "            y_test_categorical = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "            n_splits = 4\n",
    "            kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "            for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X_train_val, y_train_val)):\n",
    "                print(f\"Training fold {fold_idx + 1}/{n_splits}\")\n",
    "\n",
    "                X_train = X_train_val[train_idx]\n",
    "                y_train = y_train_val_categorical[train_idx]\n",
    "                X_val = X_train_val[val_idx]\n",
    "                y_val = y_train_val_categorical[val_idx]\n",
    "\n",
    "                early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "                model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "            # Вычисление метрик\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, average='macro')\n",
    "            recall = recall_score(y_test, y_pred, average='macro')\n",
    "            f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "            acc_list.append(accuracy)\n",
    "            precision_list.append(precision)\n",
    "            recall_list.append(recall)\n",
    "            f1_list.append(f1)\n",
    "\n",
    "perceptron_results = pd.DataFrame({\n",
    "    'embeddings_model': embeddings_models_list,\n",
    "    'classification_model': classification_models,\n",
    "    'preprocessing_has': preprocessing_types,\n",
    "    'accuracy': acc_list,\n",
    "    'precision_macro': precision_list,\n",
    "    'recall_macro': recall_list,\n",
    "    'f1_macro': f1_list\n",
    "})\n",
    "\n",
    "perceptron_results.to_csv('perceptron_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings_model</th>\n",
       "      <th>classification_model</th>\n",
       "      <th>preprocessing_has</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all_mpnet_base_v2</td>\n",
       "      <td>Perceptron_64</td>\n",
       "      <td>no</td>\n",
       "      <td>0.952716</td>\n",
       "      <td>0.953844</td>\n",
       "      <td>0.950604</td>\n",
       "      <td>0.952126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all_mpnet_base_v2</td>\n",
       "      <td>Perceptron_64</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.950817</td>\n",
       "      <td>0.950440</td>\n",
       "      <td>0.949388</td>\n",
       "      <td>0.949839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all_mpnet_base_v2</td>\n",
       "      <td>Perceptron_128</td>\n",
       "      <td>no</td>\n",
       "      <td>0.952336</td>\n",
       "      <td>0.951820</td>\n",
       "      <td>0.951719</td>\n",
       "      <td>0.951746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all_mpnet_base_v2</td>\n",
       "      <td>Perceptron_128</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.952146</td>\n",
       "      <td>0.951854</td>\n",
       "      <td>0.950533</td>\n",
       "      <td>0.951142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>all_mpnet_base_v2</td>\n",
       "      <td>Perceptron_256</td>\n",
       "      <td>no</td>\n",
       "      <td>0.955564</td>\n",
       "      <td>0.956242</td>\n",
       "      <td>0.953391</td>\n",
       "      <td>0.954723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>all_mpnet_base_v2</td>\n",
       "      <td>Perceptron_256</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.953855</td>\n",
       "      <td>0.953861</td>\n",
       "      <td>0.952301</td>\n",
       "      <td>0.953045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>all_mpnet_base_v2</td>\n",
       "      <td>Perceptron_512</td>\n",
       "      <td>no</td>\n",
       "      <td>0.957653</td>\n",
       "      <td>0.957687</td>\n",
       "      <td>0.956161</td>\n",
       "      <td>0.956849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>all_mpnet_base_v2</td>\n",
       "      <td>Perceptron_512</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.954425</td>\n",
       "      <td>0.953636</td>\n",
       "      <td>0.953000</td>\n",
       "      <td>0.953307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>all_MiniLM_L6_v2</td>\n",
       "      <td>Perceptron_64</td>\n",
       "      <td>no</td>\n",
       "      <td>0.946449</td>\n",
       "      <td>0.947600</td>\n",
       "      <td>0.944073</td>\n",
       "      <td>0.945732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>all_MiniLM_L6_v2</td>\n",
       "      <td>Perceptron_64</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.940182</td>\n",
       "      <td>0.940151</td>\n",
       "      <td>0.939180</td>\n",
       "      <td>0.939510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>all_MiniLM_L6_v2</td>\n",
       "      <td>Perceptron_128</td>\n",
       "      <td>no</td>\n",
       "      <td>0.950437</td>\n",
       "      <td>0.951101</td>\n",
       "      <td>0.948699</td>\n",
       "      <td>0.949807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>all_MiniLM_L6_v2</td>\n",
       "      <td>Perceptron_128</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.942651</td>\n",
       "      <td>0.941975</td>\n",
       "      <td>0.941511</td>\n",
       "      <td>0.941692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>all_MiniLM_L6_v2</td>\n",
       "      <td>Perceptron_256</td>\n",
       "      <td>no</td>\n",
       "      <td>0.950627</td>\n",
       "      <td>0.951403</td>\n",
       "      <td>0.948340</td>\n",
       "      <td>0.949718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>all_MiniLM_L6_v2</td>\n",
       "      <td>Perceptron_256</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.947588</td>\n",
       "      <td>0.946051</td>\n",
       "      <td>0.947259</td>\n",
       "      <td>0.946516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>all_MiniLM_L6_v2</td>\n",
       "      <td>Perceptron_512</td>\n",
       "      <td>no</td>\n",
       "      <td>0.952336</td>\n",
       "      <td>0.951255</td>\n",
       "      <td>0.951973</td>\n",
       "      <td>0.951493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>all_MiniLM_L6_v2</td>\n",
       "      <td>Perceptron_512</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.949107</td>\n",
       "      <td>0.950479</td>\n",
       "      <td>0.946711</td>\n",
       "      <td>0.948542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Universal-sentence-encoder</td>\n",
       "      <td>Perceptron_64</td>\n",
       "      <td>no</td>\n",
       "      <td>0.942841</td>\n",
       "      <td>0.942829</td>\n",
       "      <td>0.942262</td>\n",
       "      <td>0.942452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Universal-sentence-encoder</td>\n",
       "      <td>Perceptron_64</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.938663</td>\n",
       "      <td>0.941253</td>\n",
       "      <td>0.935240</td>\n",
       "      <td>0.938103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Universal-sentence-encoder</td>\n",
       "      <td>Perceptron_128</td>\n",
       "      <td>no</td>\n",
       "      <td>0.946259</td>\n",
       "      <td>0.948079</td>\n",
       "      <td>0.943459</td>\n",
       "      <td>0.945606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Universal-sentence-encoder</td>\n",
       "      <td>Perceptron_128</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.939613</td>\n",
       "      <td>0.941849</td>\n",
       "      <td>0.936708</td>\n",
       "      <td>0.939124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Universal-sentence-encoder</td>\n",
       "      <td>Perceptron_256</td>\n",
       "      <td>no</td>\n",
       "      <td>0.950437</td>\n",
       "      <td>0.951881</td>\n",
       "      <td>0.948358</td>\n",
       "      <td>0.950041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Universal-sentence-encoder</td>\n",
       "      <td>Perceptron_256</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.944170</td>\n",
       "      <td>0.944481</td>\n",
       "      <td>0.942657</td>\n",
       "      <td>0.943517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Universal-sentence-encoder</td>\n",
       "      <td>Perceptron_512</td>\n",
       "      <td>no</td>\n",
       "      <td>0.950627</td>\n",
       "      <td>0.951401</td>\n",
       "      <td>0.948911</td>\n",
       "      <td>0.950093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Universal-sentence-encoder</td>\n",
       "      <td>Perceptron_512</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.943600</td>\n",
       "      <td>0.945297</td>\n",
       "      <td>0.940985</td>\n",
       "      <td>0.943031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              embeddings_model classification_model preprocessing_has  \\\n",
       "0            all_mpnet_base_v2        Perceptron_64                no   \n",
       "1            all_mpnet_base_v2        Perceptron_64               yes   \n",
       "2            all_mpnet_base_v2       Perceptron_128                no   \n",
       "3            all_mpnet_base_v2       Perceptron_128               yes   \n",
       "4            all_mpnet_base_v2       Perceptron_256                no   \n",
       "5            all_mpnet_base_v2       Perceptron_256               yes   \n",
       "6            all_mpnet_base_v2       Perceptron_512                no   \n",
       "7            all_mpnet_base_v2       Perceptron_512               yes   \n",
       "8             all_MiniLM_L6_v2        Perceptron_64                no   \n",
       "9             all_MiniLM_L6_v2        Perceptron_64               yes   \n",
       "10            all_MiniLM_L6_v2       Perceptron_128                no   \n",
       "11            all_MiniLM_L6_v2       Perceptron_128               yes   \n",
       "12            all_MiniLM_L6_v2       Perceptron_256                no   \n",
       "13            all_MiniLM_L6_v2       Perceptron_256               yes   \n",
       "14            all_MiniLM_L6_v2       Perceptron_512                no   \n",
       "15            all_MiniLM_L6_v2       Perceptron_512               yes   \n",
       "16  Universal-sentence-encoder        Perceptron_64                no   \n",
       "17  Universal-sentence-encoder        Perceptron_64               yes   \n",
       "18  Universal-sentence-encoder       Perceptron_128                no   \n",
       "19  Universal-sentence-encoder       Perceptron_128               yes   \n",
       "20  Universal-sentence-encoder       Perceptron_256                no   \n",
       "21  Universal-sentence-encoder       Perceptron_256               yes   \n",
       "22  Universal-sentence-encoder       Perceptron_512                no   \n",
       "23  Universal-sentence-encoder       Perceptron_512               yes   \n",
       "\n",
       "    accuracy  precision_macro  recall_macro  f1_macro  \n",
       "0   0.952716         0.953844      0.950604  0.952126  \n",
       "1   0.950817         0.950440      0.949388  0.949839  \n",
       "2   0.952336         0.951820      0.951719  0.951746  \n",
       "3   0.952146         0.951854      0.950533  0.951142  \n",
       "4   0.955564         0.956242      0.953391  0.954723  \n",
       "5   0.953855         0.953861      0.952301  0.953045  \n",
       "6   0.957653         0.957687      0.956161  0.956849  \n",
       "7   0.954425         0.953636      0.953000  0.953307  \n",
       "8   0.946449         0.947600      0.944073  0.945732  \n",
       "9   0.940182         0.940151      0.939180  0.939510  \n",
       "10  0.950437         0.951101      0.948699  0.949807  \n",
       "11  0.942651         0.941975      0.941511  0.941692  \n",
       "12  0.950627         0.951403      0.948340  0.949718  \n",
       "13  0.947588         0.946051      0.947259  0.946516  \n",
       "14  0.952336         0.951255      0.951973  0.951493  \n",
       "15  0.949107         0.950479      0.946711  0.948542  \n",
       "16  0.942841         0.942829      0.942262  0.942452  \n",
       "17  0.938663         0.941253      0.935240  0.938103  \n",
       "18  0.946259         0.948079      0.943459  0.945606  \n",
       "19  0.939613         0.941849      0.936708  0.939124  \n",
       "20  0.950437         0.951881      0.948358  0.950041  \n",
       "21  0.944170         0.944481      0.942657  0.943517  \n",
       "22  0.950627         0.951401      0.948911  0.950093  \n",
       "23  0.943600         0.945297      0.940985  0.943031  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Формирование общей таблицы с результатами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_1 = pd.read_csv('lstm_results.csv')\n",
    "res_2 = pd.read_csv('gru_results.csv')\n",
    "res_3 = pd.read_csv('perceptron_results.csv')\n",
    "\n",
    "merged_df = pd.concat([res_1, res_2, res_3], ignore_index=True)\n",
    "sorted_df = merged_df.sort_values(by='f1_macro', ascending=False, ignore_index=True)\n",
    "sorted_df = sorted_df.iloc[:,1:]\n",
    "sorted_df[['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']] = sorted_df[['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']].round(5)\n",
    "\n",
    "def color_gradient(value, min_value, max_value):\n",
    "    norm_value = (value - min_value) / (max_value - min_value)\n",
    "    palette = sns.color_palette(\"light:#5A9\", as_cmap=True)\n",
    "    rgb = palette(norm_value)\n",
    "    color = f'background-color: rgb({int(rgb[0]*250)}, {int(rgb[1]*250)}, {int(rgb[2]*250)})'\n",
    "    return color\n",
    "\n",
    "sorted_df_styled = sorted_df.style.apply(lambda x: [color_gradient(v, sorted_df['f1_macro'].min(), sorted_df['f1_macro'].max()) if x.name == 'f1_macro' else '' for v in x], axis=0)\n",
    "\n",
    "sorted_df_styled.set_table_styles([\n",
    "    {'selector': 'table', 'props': [('border', '1px solid #cccccc')]},\n",
    "    {'selector': 'th', 'props': [('border', '1px solid #cccccc'), ('background-color', '#f2f2f2'), ('padding', '8px')]},\n",
    "    {'selector': 'td', 'props': [('border', '1px solid #cccccc'), ('padding', '8px')]},\n",
    "    {'selector': 'tr:nth-child(even)', 'props': [('background-color', '#ffffff')]},\n",
    "    {'selector': 'tr:nth-child(odd)', 'props': [('background-color', '#f9f9f9')]},\n",
    "])\n",
    "\n",
    "sorted_df_styled\n",
    "\n",
    "sorted_df_styled.to_html('results.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

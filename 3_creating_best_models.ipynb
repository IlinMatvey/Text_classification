{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Обучение лучших моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Импортирование необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('all_embeddings_text.csv')\n",
    "df_2 = pd.read_csv('all_embeddings_prep_text.csv')\n",
    "\n",
    "columns_to_add = ['1_prep_text', '2_prep_text', '3_prep_text']\n",
    "df = df.join(df_2[columns_to_add])\n",
    "\n",
    "def parse_string_to_list(s):\n",
    "    clean_s = s.strip('[]') \n",
    "    numbers = clean_s.split() \n",
    "    return [float(num) for num in numbers]\n",
    "\n",
    "for i in range(1,4):\n",
    "    df[f'{i}_text'] = df[f'{i}_text'].apply(parse_string_to_list)\n",
    "    df[f'{i}_prep_text'] = df[f'{i}_prep_text'].apply(parse_string_to_list)\n",
    "\n",
    "df['Label'] = df['Label'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8895 - loss: 0.4063 - val_accuracy: 0.9408 - val_loss: 0.2104\n",
      "Epoch 2/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9452 - loss: 0.1919 - val_accuracy: 0.9435 - val_loss: 0.1927\n",
      "Epoch 3/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9535 - loss: 0.1658 - val_accuracy: 0.9458 - val_loss: 0.1893\n",
      "Epoch 4/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9570 - loss: 0.1510 - val_accuracy: 0.9474 - val_loss: 0.1799\n",
      "Epoch 5/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.1325 - val_accuracy: 0.9473 - val_loss: 0.1809\n",
      "Epoch 6/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9647 - loss: 0.1140 - val_accuracy: 0.9502 - val_loss: 0.1726\n",
      "Epoch 7/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9689 - loss: 0.1081 - val_accuracy: 0.9526 - val_loss: 0.1694\n",
      "Epoch 8/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9730 - loss: 0.0892 - val_accuracy: 0.9544 - val_loss: 0.1700\n",
      "Epoch 9/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9757 - loss: 0.0819 - val_accuracy: 0.9515 - val_loss: 0.1683\n",
      "Epoch 10/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9777 - loss: 0.0756 - val_accuracy: 0.9534 - val_loss: 0.1724\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9702 - loss: 0.1088 - val_accuracy: 0.9771 - val_loss: 0.0804\n",
      "Epoch 2/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9723 - loss: 0.0965 - val_accuracy: 0.9720 - val_loss: 0.0863\n",
      "Epoch 3/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9766 - loss: 0.0817 - val_accuracy: 0.9722 - val_loss: 0.0873\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9705 - loss: 0.1030 - val_accuracy: 0.9792 - val_loss: 0.0612\n",
      "Epoch 2/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9736 - loss: 0.0864 - val_accuracy: 0.9812 - val_loss: 0.0649\n",
      "Epoch 3/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9781 - loss: 0.0739 - val_accuracy: 0.9784 - val_loss: 0.0678\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9755 - loss: 0.0857 - val_accuracy: 0.9828 - val_loss: 0.0594\n",
      "Epoch 2/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9756 - loss: 0.0796 - val_accuracy: 0.9810 - val_loss: 0.0615\n",
      "Epoch 3/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9801 - loss: 0.0700 - val_accuracy: 0.9804 - val_loss: 0.0670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/4\n",
      "Epoch 1/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8518 - loss: 0.4765 - val_accuracy: 0.9312 - val_loss: 0.2331\n",
      "Epoch 2/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9359 - loss: 0.2291 - val_accuracy: 0.9360 - val_loss: 0.2201\n",
      "Epoch 3/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9451 - loss: 0.1942 - val_accuracy: 0.9386 - val_loss: 0.2129\n",
      "Epoch 4/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9483 - loss: 0.1801 - val_accuracy: 0.9401 - val_loss: 0.2097\n",
      "Epoch 5/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9530 - loss: 0.1674 - val_accuracy: 0.9426 - val_loss: 0.2021\n",
      "Epoch 6/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9556 - loss: 0.1588 - val_accuracy: 0.9429 - val_loss: 0.1972\n",
      "Epoch 7/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9619 - loss: 0.1376 - val_accuracy: 0.9450 - val_loss: 0.1950\n",
      "Epoch 8/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9656 - loss: 0.1187 - val_accuracy: 0.9450 - val_loss: 0.1932\n",
      "Epoch 9/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9672 - loss: 0.1129 - val_accuracy: 0.9456 - val_loss: 0.1903\n",
      "Epoch 10/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9724 - loss: 0.0981 - val_accuracy: 0.9455 - val_loss: 0.1934\n",
      "Training fold 2/4\n",
      "Epoch 1/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9643 - loss: 0.1284 - val_accuracy: 0.9708 - val_loss: 0.1017\n",
      "Epoch 2/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9670 - loss: 0.1152 - val_accuracy: 0.9711 - val_loss: 0.1042\n",
      "Epoch 3/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9717 - loss: 0.0995 - val_accuracy: 0.9681 - val_loss: 0.1087\n",
      "Training fold 3/4\n",
      "Epoch 1/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9656 - loss: 0.1275 - val_accuracy: 0.9771 - val_loss: 0.0809\n",
      "Epoch 2/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9715 - loss: 0.1063 - val_accuracy: 0.9746 - val_loss: 0.0847\n",
      "Epoch 3/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9724 - loss: 0.1011 - val_accuracy: 0.9734 - val_loss: 0.0873\n",
      "Training fold 4/4\n",
      "Epoch 1/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9692 - loss: 0.1135 - val_accuracy: 0.9799 - val_loss: 0.0776\n",
      "Epoch 2/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9721 - loss: 0.0968 - val_accuracy: 0.9780 - val_loss: 0.0830\n",
      "Epoch 3/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9739 - loss: 0.0837 - val_accuracy: 0.9768 - val_loss: 0.0872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Количество классов\n",
    "num_classes = 4  \n",
    "\n",
    "for i in range(1, 3):\n",
    "\n",
    "    X_train_val = np.array(df[f'{i}_text'].to_list())\n",
    "    y_train_val = np.array(df['Label'])\n",
    "\n",
    "    n_features = len(X_train_val[0])\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(n_features,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4, activation='softmax'))  \n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    y_train_val_categorical = to_categorical(y_train_val, num_classes=num_classes)\n",
    "\n",
    "    n_splits = 4\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X_train_val, y_train_val)):\n",
    "        print(f\"Training fold {fold_idx + 1}/{n_splits}\")\n",
    "\n",
    "        X_train = X_train_val[train_idx]\n",
    "        y_train = y_train_val_categorical[train_idx]\n",
    "        X_val = X_train_val[val_idx]\n",
    "        y_val = y_train_val_categorical[val_idx]\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, callbacks=[early_stopping])\n",
    "\n",
    "    if i == 1:\n",
    "        model.save('best_model.h5')\n",
    "    else:\n",
    "        model.save('fast_model.h5')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
